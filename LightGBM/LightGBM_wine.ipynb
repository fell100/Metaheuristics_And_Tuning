{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definindo o Problema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Sev1tJEIXbP",
        "outputId": "a8d34b52-5234-4e1c-ba54-12555337e150"
      },
      "outputs": [],
      "source": [
        "#!pip install lightgbm;\n",
        "#!pip install pymoo;\n",
        "#!pip install -U pyrecorder;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QrgfvJRNIFyW"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "#from yellowbrick.classifier import ConfusionMatrix\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "#from google.colab import drive\n",
        "import pickle\n",
        "from pymoo.algorithms.soo.nonconvex.pso import PSO, PSOAnimation\n",
        "#from pymoo.factory import Rastrigin\n",
        "from pymoo.optimize import minimize\n",
        "import matplotlib.pyplot as plt\n",
        "from pymoo.factory import get_termination\n",
        "#from pymoo.util.display import Display\n",
        "from pymoo.core.callback import Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bnmY0okxIjkH"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io1a1cJQIQoZ",
        "outputId": "7762ca48-fc4c-4746-a658-5238c24392fc"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4TYgT1s1ISuF"
      },
      "outputs": [],
      "source": [
        "#with open('/content/gdrive/MyDrive/datasets/credit.pkl', 'rb') as f:\n",
        "#    x_wine_train, x_wine_test, y_wine_train, y_wine_test = pickle.load(f)\n",
        "    \n",
        "#with open('./wine.pkl', 'rb') as f:\n",
        "#    x_wine, y_wine = pickle.load(f)\n",
        "    \n",
        "with open('./wine.pkl', 'rb') as f:\n",
        "    x_wine, y_wine = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHg0NYkn-4CK"
      },
      "source": [
        "Definindo as restrições "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BkFUaoY1fTFl"
      },
      "outputs": [],
      "source": [
        "OBJECTIVE = ['Accuracy']\n",
        "DIMENSIONS = 25 #num_leaves, min_child_samples, n_estimators, learning_rate, subsample_for_bin, min_split_gain, min_child_weight, subsample, reg_alpha, reg_lambda\n",
        "ITERATIONS = 10\n",
        "POPULATION = 15\n",
        "num_leaves_min = 10\n",
        "num_leaves_max = 200\n",
        "min_child_samples_min = 10\n",
        "min_child_samples_max = 50\n",
        "n_estimators_min = 20\n",
        "n_estimators_max = 1000\n",
        "\n",
        "learning_rate_min = 0.001\n",
        "learning_rate_max = 0.5\n",
        "subsample_for_bin_min = 50000\n",
        "subsample_for_bin_max = 500000\n",
        "min_split_gain_min = 0.01\n",
        "min_split_gain_max = 0.5\n",
        "min_child_weight_min = 0.001\n",
        "min_child_weight_max = 0.15\n",
        "subsample_min = 1.0\n",
        "subsample_max = 2.0\n",
        "reg_alpha_min =0.01\n",
        "reg_alpha_max = 100.0 \n",
        "reg_lambda_min = 0.01\n",
        "reg_lambda_max = 100.0\n",
        "\n",
        "BOUNDS = []\n",
        "SEED = 1\n",
        "INDIVIDUALS = []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://lightgbm.readthedocs.io/en/latest/Parameters.html#force_col_wise\n",
        "\n",
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_depth_min = 1\n",
        "bagging_fraction_min = 0.0\n",
        "pos_bagging_fraction_min = 0.0\n",
        "neg_bagging_fraction_min = 0.0\n",
        "bagging_freq_min = 0\n",
        "feature_fraction_min = 0.0\n",
        "feature_fraction_bynode_min = 0.0\n",
        "extra_trees_min = 0 # boolean\n",
        "first_metric_only_min = 0 # boolean\n",
        "max_delta_step_min = -10.0\n",
        "linear_lambda_min = 0.0\n",
        "min_data_per_group_min = 1\n",
        "max_cat_threshold_min = 1\n",
        "cat_l2_min = 0.0\n",
        "cat_smooth_min = 0.0\n",
        "max_cat_to_onehot_min = 1\n",
        "top_k_min = 1\n",
        "\n",
        "max_depth_max = 50 #int\n",
        "bagging_fraction_max = 1.0\n",
        "pos_bagging_fraction_max = 1.0\n",
        "neg_bagging_fraction_max = 1.0\n",
        "bagging_freq_max = 100 #int\n",
        "feature_fraction_max = 1.0\n",
        "feature_fraction_bynode_max = 1.0\n",
        "extra_trees_max = 1 # boolean\n",
        "first_metric_only_max = 1 # boolean\n",
        "max_delta_step_max = 10.0\n",
        "linear_lambda_max = 10.0\n",
        "min_data_per_group_max = 200 #int\n",
        "max_cat_threshold_max = 100 #int\n",
        "cat_l2_max = 20.0\n",
        "cat_smooth_max = 20.0\n",
        "max_cat_to_onehot_max = 20 #int\n",
        "top_k_max = 40 #int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSbKK_Og-7Oe"
      },
      "source": [
        "Definindo o problema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Elrs3UT_j7t6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pymoo.core.problem import ElementwiseProblem\n",
        "\n",
        "class OptimizeWithAccuracy(ElementwiseProblem):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(n_var= DIMENSIONS,\n",
        "                         n_obj=1,\n",
        "                         n_constr=25,\n",
        "                         xl=np.array([num_leaves_min, min_child_samples_min, n_estimators_min, learning_rate_min, subsample_for_bin_min,\n",
        "                                      min_split_gain_min, min_child_weight_min, reg_alpha_min, reg_lambda_min, max_depth_min,\n",
        "                                        bagging_fraction_min,\n",
        "                                        pos_bagging_fraction_min,\n",
        "                                        neg_bagging_fraction_min,\n",
        "                                        bagging_freq_min,\n",
        "                                        feature_fraction_min,\n",
        "                                        feature_fraction_bynode_min,\n",
        "                                        extra_trees_min,\n",
        "                                        max_delta_step_min,\n",
        "                                        linear_lambda_min,\n",
        "                                        min_data_per_group_min,\n",
        "                                        max_cat_threshold_min,\n",
        "                                        cat_l2_min,\n",
        "                                        cat_smooth_min,\n",
        "                                        max_cat_to_onehot_min,\n",
        "                                        top_k_min]),\n",
        "                         xu=np.array([num_leaves_max, min_child_samples_max, n_estimators_max, learning_rate_max, subsample_for_bin_max,\n",
        "                                      min_split_gain_max, min_child_weight_max, reg_alpha_max, reg_lambda_max,\n",
        "                                      max_depth_max,\n",
        "                                        bagging_fraction_max,\n",
        "                                        pos_bagging_fraction_max,\n",
        "                                        neg_bagging_fraction_max,\n",
        "                                        bagging_freq_max,\n",
        "                                        feature_fraction_max,\n",
        "                                        feature_fraction_bynode_max,\n",
        "                                        extra_trees_max,\n",
        "                                        max_delta_step_max,\n",
        "                                        linear_lambda_max,\n",
        "                                        min_data_per_group_max,\n",
        "                                        max_cat_threshold_max,\n",
        "                                        cat_l2_max,\n",
        "                                        cat_smooth_max,\n",
        "                                        max_cat_to_onehot_max,\n",
        "                                        top_k_max])\n",
        "                        )\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        #num_leaves, min_child_samples, n_estimators, learning_rate, subsample_for_bin, min_split_gain, min_child_weight, reg_alpha, reg_lambda\n",
        "        \n",
        "        model_lgb = lgb.LGBMClassifier(num_leaves        = int(np.round(x[0])), \n",
        "                                       min_child_samples = int(np.round(x[1])), \n",
        "                                       n_estimators      = int(np.round(x[2])),\n",
        "                                       learning_rate     = x[3] ,\n",
        "                                       subsample_for_bin = int(np.round(x[4])),\n",
        "                                       min_split_gain    = x[5],\n",
        "                                       min_child_weight  = x[6],\n",
        "                                       reg_alpha         = x[7],\n",
        "                                       reg_lambda        = x[8],\n",
        "                                       max_depth = int(np.round(x[9])),\n",
        "                                       bagging_fraction = x[10],\n",
        "                                       pos_bagging_fraction = x[11],\n",
        "                                       neg_bagging_fraction = x[12],\n",
        "                                       bagging_freq = int(np.round(x[13])), \n",
        "                                       feature_fraction = x[14],\n",
        "                                       feature_fraction_bynode = x[15],\n",
        "                                       extra_trees = bool(np.round(x[16])), #boolean\n",
        "                                       max_delta_step = x[17],\n",
        "                                       linear_lambda = x[18],\n",
        "                                       min_data_per_group = int(np.round(x[19])), \n",
        "                                       max_cat_threshold = int(np.round(x[20])), \n",
        "                                       cat_l2 = x[21],\n",
        "                                       cat_smooth = x[22],\n",
        "                                       max_cat_to_onehot = int(np.round(x[23])),\n",
        "                                       top_k = int(np.round(x[24])),\n",
        "                                       n_jobs = -1,\n",
        "                                       )\n",
        "        \n",
        "        kfold = KFold(n_splits = 3, shuffle = True)\n",
        "        \n",
        "        scores = cross_val_score(model_lgb, x_wine, y_wine, cv = kfold, n_jobs=-1)  \n",
        "        \n",
        "        result = scores.mean()\n",
        "        out['F'] = -1 * result\n",
        "\n",
        "problemAccuracy = OptimizeWithAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OptimizeWithF1(ElementwiseProblem):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(n_var= DIMENSIONS,\n",
        "                         n_obj=1,\n",
        "                         n_constr=25,\n",
        "                         xl=np.array([num_leaves_min, min_child_samples_min, n_estimators_min, learning_rate_min, subsample_for_bin_min,\n",
        "                                      min_split_gain_min, min_child_weight_min, reg_alpha_min, reg_lambda_min, max_depth_min,\n",
        "                                        bagging_fraction_min,\n",
        "                                        pos_bagging_fraction_min,\n",
        "                                        neg_bagging_fraction_min,\n",
        "                                        bagging_freq_min,\n",
        "                                        feature_fraction_min,\n",
        "                                        feature_fraction_bynode_min,\n",
        "                                        extra_trees_min,\n",
        "                                        max_delta_step_min,\n",
        "                                        linear_lambda_min,\n",
        "                                        min_data_per_group_min,\n",
        "                                        max_cat_threshold_min,\n",
        "                                        cat_l2_min,\n",
        "                                        cat_smooth_min,\n",
        "                                        max_cat_to_onehot_min,\n",
        "                                        top_k_min]),\n",
        "                         xu=np.array([num_leaves_max, min_child_samples_max, n_estimators_max, learning_rate_max, subsample_for_bin_max,\n",
        "                                      min_split_gain_max, min_child_weight_max, reg_alpha_max, reg_lambda_max,\n",
        "                                      max_depth_max,\n",
        "                                        bagging_fraction_max,\n",
        "                                        pos_bagging_fraction_max,\n",
        "                                        neg_bagging_fraction_max,\n",
        "                                        bagging_freq_max,\n",
        "                                        feature_fraction_max,\n",
        "                                        feature_fraction_bynode_max,\n",
        "                                        extra_trees_max,\n",
        "                                        max_delta_step_max,\n",
        "                                        linear_lambda_max,\n",
        "                                        min_data_per_group_max,\n",
        "                                        max_cat_threshold_max,\n",
        "                                        cat_l2_max,\n",
        "                                        cat_smooth_max,\n",
        "                                        max_cat_to_onehot_max,\n",
        "                                        top_k_max])\n",
        "                        )\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        #num_leaves, min_child_samples, n_estimators, learning_rate, subsample_for_bin, min_split_gain, min_child_weight, reg_alpha, reg_lambda\n",
        "        \n",
        "        model_lgb = lgb.LGBMClassifier(num_leaves        = int(np.round(x[0])), \n",
        "                                       min_child_samples = int(np.round(x[1])), \n",
        "                                       n_estimators      = int(np.round(x[2])),\n",
        "                                       learning_rate     = x[3] ,\n",
        "                                       subsample_for_bin = int(np.round(x[4])),\n",
        "                                       min_split_gain    = x[5],\n",
        "                                       min_child_weight  = x[6],\n",
        "                                       reg_alpha         = x[7],\n",
        "                                       reg_lambda        = x[8],\n",
        "                                       max_depth = int(np.round(x[9])),\n",
        "                                       bagging_fraction = x[10],\n",
        "                                       pos_bagging_fraction = x[11],\n",
        "                                       neg_bagging_fraction = x[12],\n",
        "                                       bagging_freq = int(np.round(x[13])), \n",
        "                                       feature_fraction = x[14],\n",
        "                                       feature_fraction_bynode = x[15],\n",
        "                                       extra_trees = bool(np.round(x[16])), #boolean\n",
        "                                       max_delta_step = x[17],\n",
        "                                       linear_lambda = x[18],\n",
        "                                       min_data_per_group = int(np.round(x[19])), \n",
        "                                       max_cat_threshold = int(np.round(x[20])), \n",
        "                                       cat_l2 = x[21],\n",
        "                                       cat_smooth = x[22],\n",
        "                                       max_cat_to_onehot = int(np.round(x[23])),\n",
        "                                       top_k = int(np.round(x[24])),\n",
        "                                       n_jobs = -1,\n",
        "                                       )\n",
        "\n",
        "        kfold = KFold(n_splits = 3, shuffle = True)\n",
        "        \n",
        "        scores = cross_val_score(model_lgb, x_wine, y_wine, cv = kfold, scoring='f1_weighted', n_jobs=-1)  \n",
        "        \n",
        "        result = scores.mean()\n",
        "        out['F'] = -1 * result\n",
        "\n",
        "problemF1 = OptimizeWithF1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OptimizeWithAUC(ElementwiseProblem):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__(n_var= DIMENSIONS,\n",
        "                         n_obj=1,\n",
        "                         n_constr=25,\n",
        "                         xl=np.array([num_leaves_min, min_child_samples_min, n_estimators_min, learning_rate_min, subsample_for_bin_min,\n",
        "                                      min_split_gain_min, min_child_weight_min, reg_alpha_min, reg_lambda_min, max_depth_min,\n",
        "                                        bagging_fraction_min,\n",
        "                                        pos_bagging_fraction_min,\n",
        "                                        neg_bagging_fraction_min,\n",
        "                                        bagging_freq_min,\n",
        "                                        feature_fraction_min,\n",
        "                                        feature_fraction_bynode_min,\n",
        "                                        extra_trees_min,\n",
        "                                        max_delta_step_min,\n",
        "                                        linear_lambda_min,\n",
        "                                        min_data_per_group_min,\n",
        "                                        max_cat_threshold_min,\n",
        "                                        cat_l2_min,\n",
        "                                        cat_smooth_min,\n",
        "                                        max_cat_to_onehot_min,\n",
        "                                        top_k_min]),\n",
        "                         xu=np.array([num_leaves_max, min_child_samples_max, n_estimators_max, learning_rate_max, subsample_for_bin_max,\n",
        "                                      min_split_gain_max, min_child_weight_max, reg_alpha_max, reg_lambda_max,\n",
        "                                      max_depth_max,\n",
        "                                        bagging_fraction_max,\n",
        "                                        pos_bagging_fraction_max,\n",
        "                                        neg_bagging_fraction_max,\n",
        "                                        bagging_freq_max,\n",
        "                                        feature_fraction_max,\n",
        "                                        feature_fraction_bynode_max,\n",
        "                                        extra_trees_max,\n",
        "                                        max_delta_step_max,\n",
        "                                        linear_lambda_max,\n",
        "                                        min_data_per_group_max,\n",
        "                                        max_cat_threshold_max,\n",
        "                                        cat_l2_max,\n",
        "                                        cat_smooth_max,\n",
        "                                        max_cat_to_onehot_max,\n",
        "                                        top_k_max])\n",
        "                        )\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        #num_leaves, min_child_samples, n_estimators, learning_rate, subsample_for_bin, min_split_gain, min_child_weight, reg_alpha, reg_lambda\n",
        "        \n",
        "        model_lgb = lgb.LGBMClassifier(num_leaves        = int(np.round(x[0])), \n",
        "                                       min_child_samples = int(np.round(x[1])), \n",
        "                                       n_estimators      = int(np.round(x[2])),\n",
        "                                       learning_rate     = x[3] ,\n",
        "                                       subsample_for_bin = int(np.round(x[4])),\n",
        "                                       min_split_gain    = x[5],\n",
        "                                       min_child_weight  = x[6],\n",
        "                                       reg_alpha         = x[7],\n",
        "                                       reg_lambda        = x[8],\n",
        "                                       max_depth = int(np.round(x[9])),\n",
        "                                       bagging_fraction = x[10],\n",
        "                                       pos_bagging_fraction = x[11],\n",
        "                                       neg_bagging_fraction = x[12],\n",
        "                                       bagging_freq = int(np.round(x[13])), \n",
        "                                       feature_fraction = x[14],\n",
        "                                       feature_fraction_bynode = x[15],\n",
        "                                       extra_trees = bool(np.round(x[16])), #boolean\n",
        "                                       max_delta_step = x[17],\n",
        "                                       linear_lambda = x[18],\n",
        "                                       min_data_per_group = int(np.round(x[19])), \n",
        "                                       max_cat_threshold = int(np.round(x[20])), \n",
        "                                       cat_l2 = x[21],\n",
        "                                       cat_smooth = x[22],\n",
        "                                       max_cat_to_onehot = int(np.round(x[23])),\n",
        "                                       top_k = int(np.round(x[24])),\n",
        "                                       n_jobs = -1,\n",
        "                                       )\n",
        "\n",
        "        kfold = KFold(n_splits = 3, shuffle = True)\n",
        "        \n",
        "        scores = cross_val_score(model_lgb, x_wine, y_wine, cv = kfold, scoring='roc_auc_ovr_weighted', n_jobs=-1)  \n",
        "        \n",
        "        result = scores.mean()\n",
        "        out['F'] = -1 * result\n",
        "\n",
        "problemAUC = OptimizeWithAUC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymoo.util.display.column import Column\n",
        "from pymoo.util.display.output import Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyOutput(Output):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        global pbar \n",
        "        pbar = tqdm(total=ITERATIONS)\n",
        "        self.score = Column(\"score\", width=13)\n",
        "        self.Parameters = Column(\"Parameters\", width=35)\n",
        "        self.columns += [self.score, self.Parameters]\n",
        "\n",
        "    def update(self, algorithm):\n",
        "        super().update(algorithm)\n",
        "        self.score.set(-np.min(algorithm.pop.get(\"F\")))\n",
        "        #self.Parameters.set(algorithm.pop.get(\"X\")[0])\n",
        "        pbar.update(1)\n",
        "        if pbar.n == ITERATIONS: pbar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HsPc7BH-MWL"
      },
      "source": [
        "## Particle Swarm Optimization (PSO)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Acurácia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J275mWjGbVJo"
      },
      "outputs": [],
      "source": [
        "ITERATIONS = 32\n",
        "POPULATION = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848,
          "referenced_widgets": [
            "b504307a10f54034ad07715278fa1dbc",
            "20a38960e7374ab594f04f4b1c5e2321",
            "7c3472a6094a4249a082f8dc630e5258",
            "ae818704a52542d696c8eb0c1c182a81",
            "992dda0d38b145b88946b67edc62ab57",
            "6f29547455ac4adb8edaa11d5839f5cb",
            "1a32143976c744e5a388d7b343e7c054",
            "1614757884124ed487149ebed485833f",
            "6f124da663194ac0b073ab7a3fb168c3",
            "76b3046c318d4fbcb66b198b50cd91e7",
            "124e5b4b5b3344f4abdc93628b112d8f"
          ]
        },
        "id": "Ub3CpvtimILV",
        "outputId": "b5231789-c65e-4089-99c9-9fcc0b99f5ca"
      },
      "outputs": [],
      "source": [
        "def run_accuracy_pso(ITERATIONS = 32, POPULATION = 32):\n",
        "    algorithm = PSO(#pop_size=POPULATION, \n",
        "                    #w=0.3, c1=4.0, c2=1.0, \n",
        "                    #adaptive=False, initial_velocity='random', \n",
        "                    #max_velocity_rate=0.75, pertube_best=False,\n",
        "                    max_velocity_rate=0.25,\n",
        "                    pop_size=POPULATION)\n",
        "    term = get_termination(\"n_gen\", ITERATIONS)\n",
        "\n",
        "    res = minimize(problemAccuracy,\n",
        "                algorithm,\n",
        "                #seed=SEED,\n",
        "                save_history=False,\n",
        "                verbose=False,\n",
        "                output=MyOutput(),\n",
        "                termination = term)\n",
        "\n",
        "\n",
        "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
        "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
        "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
        "\n",
        "    #print(f'Best Accuracy Score {-score_best_individual}')\n",
        "    #print(f'Model parameters: \\n {parameters_best_individual}')\n",
        "    return score_best_individual, parameters_best_individual, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felps\\AppData\\Local\\Temp\\ipykernel_13244\\2673210061.py:8: DeprecationWarning: Call to deprecated function (or staticmethod) get_termination. (Please use `from pymoo.termination import get_termination`)\n",
            "  term = get_termination(\"n_gen\", ITERATIONS)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87adf2af435046c78bf07c77619966e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "score_best_individual, parameters_best_individual, res = run_accuracy_pso(ITERATIONS = 1, POPULATION = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F1E38iDlQUl",
        "outputId": "d83fa2a1-f2c2-49a3-c8a9-ddc5b449b2bb"
      },
      "outputs": [],
      "source": [
        "#final_model = lgb.LGBMClassifier(num_leaves       = int(np.round(parameters_best_individual[0])), \n",
        "#                                min_child_samples = int(np.round(parameters_best_individual[1])), \n",
        "#                                n_estimators      = int(np.round(parameters_best_individual[2])),\n",
        "#                                learning_rate     = parameters_best_individual[3] ,\n",
        "#                                subsample_for_bin = int(np.round(parameters_best_individual[4])),\n",
        "#                                min_split_gain    = parameters_best_individual[5],\n",
        "#                                min_child_weight  = parameters_best_individual[6],\n",
        "#                                reg_alpha         = parameters_best_individual[7],\n",
        "#                                reg_lambda        = parameters_best_individual[8],\n",
        "#                                max_depth=- 1\n",
        "#                                )\n",
        "#\n",
        "#\n",
        "#kfold = KFold(n_splits = 3, shuffle = True)\n",
        "#\n",
        "#scores = cross_val_score(final_model, x_wine, y_wine, cv = kfold, n_jobs=-1)  \n",
        "#\n",
        "#result = scores.mean()\n",
        "###print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3tT-sQocbOnb"
      },
      "outputs": [],
      "source": [
        "#trlist = np.array([])\n",
        "#for i in range(len(res.history)):\n",
        "#  trlist = np.append(trlist, -res.history[i].pop.get('F').reshape(-1)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zJu3r3qI4crG"
      },
      "outputs": [],
      "source": [
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "##for i in range(1):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kEcgjgreFrvp"
      },
      "outputs": [],
      "source": [
        "#Accuracy_PSO = scorelist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "qLYLRAg_51U5",
        "outputId": "fbd0c7ea-1543-4268-c387-0dd27f8a2a5e"
      },
      "outputs": [],
      "source": [
        "#plt.plot(Accuracy_PSO);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Ie2LDl1g6Yni",
        "outputId": "bcc10420-9cd1-4808-9914-9f90097b8e46"
      },
      "outputs": [],
      "source": [
        "#tracking = [-np.min(individual.pop.get('F')) for individual in res.history ]\n",
        "#tracking_PSO_Accuracy = tracking\n",
        "#plt.plot(tracking)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### F1 Score "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_f1_pso(ITERATIONS = 32, POPULATION = 32):\n",
        "    algorithm = PSO(#pop_size=POPULATION, \n",
        "                    #w=0.3, c1=4.0, c2=1.0, \n",
        "                    #adaptive=False, initial_velocity='random', \n",
        "                    #max_velocity_rate=0.75, pertube_best=False,\n",
        "                    max_velocity_rate=0.25,\n",
        "                    pop_size=POPULATION)\n",
        "    term = get_termination(\"n_gen\", ITERATIONS)\n",
        "\n",
        "    res = minimize(problemF1,\n",
        "                algorithm,\n",
        "                #seed=SEED,\n",
        "                save_history=False,\n",
        "                verbose=False,\n",
        "                output=MyOutput(),\n",
        "                termination = term)\n",
        "\n",
        "\n",
        "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
        "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
        "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
        "\n",
        "    #print(f'Best F1 Score {-score_best_individual}')\n",
        "    #print(f'Model parameters: \\n {parameters_best_individual}')\n",
        "    return score_best_individual, parameters_best_individual, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felps\\AppData\\Local\\Temp\\ipykernel_13244\\3496873573.py:8: DeprecationWarning: Call to deprecated function (or staticmethod) get_termination. (Please use `from pymoo.termination import get_termination`)\n",
            "  term = get_termination(\"n_gen\", ITERATIONS)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c55454b33bca4874ac8c9aa23171e14d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "score_best_individual, parameters_best_individual, res = run_f1_pso(ITERATIONS = 1, POPULATION = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trlist = np.array([])\n",
        "#for i in range(len(res.history)):\n",
        "#  trlist = np.append(trlist, -res.history[i].pop.get('F').reshape(-1)) \n",
        "#  \n",
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "##for i in range(1):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])\n",
        "#    \n",
        "#F1_PSO = scorelist\n",
        "#\n",
        "#plt.plot(scorelist);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tracking = [-np.min(individual.pop.get('F')) for individual in res.history ]\n",
        "#tracking_PSO_F1 = tracking\n",
        "#plt.plot(tracking)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_auc_pso(ITERATIONS = 32, POPULATION = 32):\n",
        "    algorithm = PSO(#pop_size=POPULATION, \n",
        "                    #w=0.3, c1=4.0, c2=1.0, \n",
        "                    #adaptive=False, initial_velocity='random', \n",
        "                    #max_velocity_rate=0.75, pertube_best=False,\n",
        "                    max_velocity_rate=0.25,\n",
        "                    pop_size=POPULATION)\n",
        "    term = get_termination(\"n_gen\", ITERATIONS)\n",
        "\n",
        "    res = minimize(problemAUC,\n",
        "                algorithm,\n",
        "                #seed=SEED,\n",
        "                save_history=False,\n",
        "                verbose=False,\n",
        "                output=MyOutput(),\n",
        "                termination = term)\n",
        "\n",
        "\n",
        "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
        "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
        "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
        "\n",
        "    #print(f'Best AUC Score {-score_best_individual}')\n",
        "    #print(f'Model parameters: \\n {parameters_best_individual}')\n",
        "    \n",
        "    return score_best_individual, parameters_best_individual, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felps\\AppData\\Local\\Temp\\ipykernel_13244\\1707635262.py:8: DeprecationWarning: Call to deprecated function (or staticmethod) get_termination. (Please use `from pymoo.termination import get_termination`)\n",
            "  term = get_termination(\"n_gen\", ITERATIONS)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9347aba9d90b40e5a0e865cf050778fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "score_best_individual, parameters_best_individual, res = run_auc_pso(ITERATIONS = 1, POPULATION = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trlist = np.array([])\n",
        "#for i in range(len(res.history)):\n",
        "#  trlist = np.append(trlist, -res.history[i].pop.get('F').reshape(-1)) \n",
        "#  \n",
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "##for i in range(1):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])\n",
        "#    \n",
        "#AUC_PSO = scorelist\n",
        "#\n",
        "#plt.plot(scorelist);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tracking = [-np.min(individual.pop.get('F')) for individual in res.history ]\n",
        "#tracking_PSO_AUC = tracking\n",
        "#plt.plot(tracking)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTAAhn6w-Be4"
      },
      "source": [
        "## Algoritmo Genético (GA)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Acurácia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1iXezRJUgWiM"
      },
      "outputs": [],
      "source": [
        "ITERATIONS = 32\n",
        "POPULATION = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymoo.algorithms.soo.nonconvex.ga import GA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848,
          "referenced_widgets": [
            "12434838d89048188eefe1af0332bfd6",
            "b6288aa156624b108015ab993c54d52b",
            "f45e5f0d4187404fb8f63acd3c26fe17",
            "aaa16b6dbffd42ef973b1826e5ed2242",
            "8721e5217b97444d948e5b85c6fd53c7",
            "d25235d18f8045de9948417d13538ef3",
            "01d3490253a8464281845cb171385d59",
            "7f079b743c6e4ad897ae55ba366a15b9",
            "54cbbc7ffbcc401abfbf3167f882019e",
            "d539e4a476cb4ae28e78769b17b97aa9",
            "fb379b55e7bd4b3bb7ed4b0ec6390b2e"
          ]
        },
        "id": "TK9YdWdMfAw3",
        "outputId": "60624262-0c77-4e32-8106-540ea70cd8f9"
      },
      "outputs": [],
      "source": [
        "def run_accuracy_ga(ITERATIONS = 32, POPULATION = 32):\n",
        "\n",
        "    algorithm = GA(pop_size=POPULATION)\n",
        "\n",
        "    term = get_termination(\"n_gen\", ITERATIONS)\n",
        "\n",
        "    res = minimize(problemAccuracy,\n",
        "                algorithm,\n",
        "                save_history=False,\n",
        "                verbose=False,\n",
        "                output=MyOutput(),\n",
        "                termination = term)\n",
        "\n",
        "\n",
        "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
        "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
        "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
        "\n",
        "    #print(f'Best Accuracy Score {-score_best_individual}')\n",
        "    #print(f'Model parameters: \\n {parameters_best_individual}')\n",
        "    \n",
        "    return score_best_individual, parameters_best_individual, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felps\\AppData\\Local\\Temp\\ipykernel_13244\\3610728493.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) get_termination. (Please use `from pymoo.termination import get_termination`)\n",
            "  term = get_termination(\"n_gen\", ITERATIONS)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d7c1544fab04fde838743e6ff063bca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "score_best_individual, parameters_best_individual, res = run_accuracy_ga(ITERATIONS = 1, POPULATION = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Aw1RtuhKgPkR",
        "outputId": "6b173010-6841-44be-fc9c-1e08c709308c"
      },
      "outputs": [],
      "source": [
        "#tracking = [-np.min(individual.pop.get('F')) for individual in res.history ]\n",
        "#tracking_GA_Accuracy = tracking\n",
        "#plt.plot(tracking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "EuxPTJqU95Ib"
      },
      "outputs": [],
      "source": [
        "#trlist = np.array([])\n",
        "#for i in range(len(res.history)):\n",
        "#  trlist = np.append(trlist, -res.history[i].pop.get('F').reshape(-1)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "COvG1svS97RF"
      },
      "outputs": [],
      "source": [
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "P4ubDrqPGUnS"
      },
      "outputs": [],
      "source": [
        "#Accuracy_GA = scorelist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "N3xxFM4e99pt",
        "outputId": "e0d19dc9-1416-42a5-c33f-945a66a17ee0"
      },
      "outputs": [],
      "source": [
        "#plt.plot(scorelist);"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### F1 Score "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
        "def run_f1_ga(ITERATIONS = 32, POPULATION = 32):\n",
        "    algorithm = GA(pop_size=POPULATION)\n",
        "\n",
        "    term = get_termination(\"n_gen\", ITERATIONS)\n",
        "\n",
        "    res = minimize(problemF1,\n",
        "                algorithm,\n",
        "                save_history=False,\n",
        "                verbose=False,\n",
        "                output=MyOutput(),\n",
        "                termination = term)\n",
        "\n",
        "\n",
        "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
        "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
        "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
        "\n",
        "    #print(f'Best F1 Score {-score_best_individual}')\n",
        "    #print(f'Model parameters: \\n {parameters_best_individual}')\n",
        "    \n",
        "    return score_best_individual, parameters_best_individual, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felps\\AppData\\Local\\Temp\\ipykernel_13244\\1994123235.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) get_termination. (Please use `from pymoo.termination import get_termination`)\n",
            "  term = get_termination(\"n_gen\", ITERATIONS)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30591887e4e44d9597f983be9433863a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "score_best_individual, parameters_best_individual, res = run_f1_ga(ITERATIONS = 1, POPULATION = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trlist = np.array([])\n",
        "#for i in range(len(res.history)):\n",
        "#  trlist = np.append(trlist, -res.history[i].pop.get('F').reshape(-1)) \n",
        "#  \n",
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "##for i in range(1):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])\n",
        "#    \n",
        "#F1_GA = scorelist\n",
        "#\n",
        "#plt.plot(scorelist);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tracking = [-np.min(individual.pop.get('F')) for individual in res.history ]\n",
        "#tracking_GA_F1 = tracking\n",
        "#plt.plot(tracking)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
        "def run_auc_ga(ITERATIONS = 32, POPULATION = 32):\n",
        "    algorithm = GA(pop_size=POPULATION)\n",
        "\n",
        "    term = get_termination(\"n_gen\", ITERATIONS)\n",
        "\n",
        "    res = minimize(problemAUC,\n",
        "                algorithm,\n",
        "                save_history=False,\n",
        "                verbose=False,\n",
        "                output=MyOutput(),\n",
        "                termination = term)\n",
        "\n",
        "\n",
        "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
        "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
        "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
        "\n",
        "    #print(f'Best AUC Score {-score_best_individual}')\n",
        "    #print(f'Model parameters: \\n {parameters_best_individual}')\n",
        "    \n",
        "    return score_best_individual, parameters_best_individual, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felps\\AppData\\Local\\Temp\\ipykernel_13244\\3250583479.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) get_termination. (Please use `from pymoo.termination import get_termination`)\n",
            "  term = get_termination(\"n_gen\", ITERATIONS)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c493ab32aea2469b85b13726011eeff2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "score_best_individual, parameters_best_individual, res = run_auc_ga(ITERATIONS = 1, POPULATION = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trlist = np.array([])\n",
        "#for i in range(len(res.history)):\n",
        "#  trlist = np.append(trlist, -res.history[i].pop.get('F').reshape(-1)) \n",
        "#  \n",
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "##for i in range(1):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])\n",
        "#    \n",
        "#AUC_GA = scorelist\n",
        "#\n",
        "#plt.plot(scorelist);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tracking = [-np.min(individual.pop.get('F')) for individual in res.history ]\n",
        "#tracking_GA_AUC = tracking\n",
        "#plt.plot(tracking)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-WtiEIO0kFu"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Acurácia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "OvuV46Aa0dBR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4nK3alPCEQm",
        "outputId": "ece560c4-eb7c-4e23-e62a-b9423bd07386"
      },
      "outputs": [],
      "source": [
        "#n_possibilities = 2\n",
        "#\n",
        "##num_leaves_grid = [i for i in range(num_leaves_min,num_leaves_max, int((num_leaves_max)/13))]\n",
        "#num_leaves_grid = [i for i in map(lambda x: int(x), np.linspace(num_leaves_min, num_leaves_max, n_possibilities))]\n",
        "#num_leaves_grid = num_leaves_grid + [100, 50, 75, 125, 11,150]\n",
        "##print('Num_Leaves_Grid: ')\n",
        "##print(num_leaves_grid, len(num_leaves_grid))\n",
        "##print('\\n')\n",
        "#\n",
        "#\n",
        "#min_child_samples_grid = [i for i in map(lambda x: int(x), np.linspace(min_child_samples_min, min_child_samples_max, n_possibilities))]\n",
        "##print('min_child_samples_grid:')\n",
        "##print(min_child_samples_grid, len(min_child_samples_grid))\n",
        "##print('\\n')\n",
        "#\n",
        "#n_estimators_grid = [i for i in map(lambda x: int(x), np.linspace(n_estimators_min, n_estimators_max, n_possibilities))]\n",
        "##print('n_estimators_grid:')\n",
        "##print(n_estimators_grid, len(n_estimators_grid))\n",
        "##print('\\n')\n",
        "#\n",
        "#learning_rate_grid = np.linspace(learning_rate_min, learning_rate_max, n_possibilities)\n",
        "##print('learning_rate_grid:')\n",
        "##print(learning_rate_grid, len(learning_rate_grid))\n",
        "##print('\\n')\n",
        "#\n",
        "#subsample_for_bin_grid = [i for i in map(lambda x: int(x), np.linspace(subsample_for_bin_min, subsample_for_bin_max, n_possibilities))]\n",
        "##print('subsample_for_bin_grid:')\n",
        "##print(subsample_for_bin_grid, len(subsample_for_bin_grid))\n",
        "##print('\\n')\n",
        "#\n",
        "#min_split_gain_grid = np.linspace(min_split_gain_min, min_split_gain_max, n_possibilities)\n",
        "##print('min_split_gain_grid:')\n",
        "##print(min_split_gain_grid, len(min_split_gain_grid))\n",
        "##print('\\n')\n",
        "#\n",
        "#min_child_weight_grid = np.linspace(min_child_weight_min, min_child_weight_max, n_possibilities)\n",
        "##print('min_child_weight_grid:')\n",
        "##print(min_child_weight_grid, len(min_child_weight_grid))\n",
        "##print('\\n')\n",
        "#\n",
        "#reg_alpha_grid = np.linspace(reg_alpha_min, reg_alpha_max, n_possibilities)\n",
        "##print('reg_alpha_grid:')\n",
        "##print(reg_alpha_grid, len(reg_alpha_grid))\n",
        "##print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sWL2gq5M0jmq"
      },
      "outputs": [],
      "source": [
        "#parametros = {'num_leaves': num_leaves_grid, #int\n",
        "#              'min_child_samples': min_child_samples_grid,#int\n",
        "#              'n_estimators': n_estimators_grid, #int\n",
        "#              'learning_rate': learning_rate_grid,\n",
        "#              'subsample_for_bin': subsample_for_bin_grid, # int\n",
        "#              'min_split_gain': min_split_gain_grid,\n",
        "#              'min_child_weight': min_child_weight_grid,\n",
        "#              'reg_alpha': reg_alpha_grid,\n",
        "#              'max_depth': [-1],\n",
        "#              'n_jobs': [-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg8ZpgTM0tK7",
        "outputId": "efa2aaa1-3397-45fe-83c3-2eea6127b6a7"
      },
      "outputs": [],
      "source": [
        "#kfold = KFold(n_splits = 3, shuffle = True)\n",
        "#grid_search = GridSearchCV(estimator = lgb.LGBMClassifier(), param_grid = parametros, cv = kfold, n_jobs= -1, verbose = 3)\n",
        "#grid_search.fit(x_wine, y_wine)\n",
        "#melhores_parametros = grid_search.best_params_\n",
        "#melhor_resultado = grid_search.best_score_\n",
        "##print(melhores_parametros)\n",
        "##print(melhor_resultado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekOamIhnrFd5",
        "outputId": "4d91ab89-5f11-4dc4-d71b-3837ba0cd1e9"
      },
      "outputs": [],
      "source": [
        "#rid_search.cv_results_.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uo45HhIasnc4"
      },
      "outputs": [],
      "source": [
        "#trlist = grid_search.cv_results_['mean_test_score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "k0PjBeFHIqKw"
      },
      "outputs": [],
      "source": [
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "##for i in range(1):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjb_n_Hkr3WK",
        "outputId": "91f6887b-7c92-4b1d-8719-825d2ce7d88e"
      },
      "outputs": [],
      "source": [
        "#tracking_GS_Accuracy = scorelist\n",
        "#plt.plot(scorelist); "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "#kfold = KFold(n_splits = 3, shuffle = True)\n",
        "#grid_search = GridSearchCV(estimator = lgb.LGBMClassifier(), param_grid = parametros, cv = kfold, n_jobs= -1, scoring='f1', verbose = 3)\n",
        "#grid_search.fit(x_wine, y_wine)\n",
        "#melhores_parametros = grid_search.best_params_\n",
        "#melhor_resultado = grid_search.best_score_\n",
        "##print(melhores_parametros)\n",
        "##print(melhor_resultado)\n",
        "#\n",
        "#trlist = grid_search.cv_results_['mean_test_score']\n",
        "#\n",
        "#\n",
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "##for i in range(1):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])\n",
        "#    \n",
        "#tracking_GS_F1 = scorelist\n",
        "#plt.plot(scorelist); "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "#kfold = KFold(n_splits = 3, shuffle = True)\n",
        "#grid_search = GridSearchCV(estimator = lgb.LGBMClassifier(), param_grid = parametros, cv = kfold, n_jobs= -1, scoring='roc_auc', verbose = 3)\n",
        "#grid_search.fit(x_wine, y_wine)\n",
        "#melhores_parametros = grid_search.best_params_\n",
        "#melhor_resultado = grid_search.best_score_\n",
        "##print(melhores_parametros)\n",
        "##print(melhor_resultado)\n",
        "#\n",
        "#trlist = grid_search.cv_results_['mean_test_score']\n",
        "#\n",
        "#\n",
        "#scorelist = []\n",
        "#\n",
        "#for i in range(len(trlist)):\n",
        "##for i in range(1):\n",
        "#  if i == 0:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  elif trlist[i] > scorelist[i-1]:\n",
        "#    scorelist.append(trlist[i])\n",
        "#  else:\n",
        "#    scorelist.append(scorelist[i-1])\n",
        "#    \n",
        "#tracking_GS_AUC = scorelist\n",
        "#plt.plot(scorelist); "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA6kphUO0vcT"
      },
      "source": [
        "## Optuna"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Acurácia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtVNXGxotkiD",
        "outputId": "3eeeb6d4-9bc6-49eb-b3d6-7c9482852c52"
      },
      "outputs": [],
      "source": [
        "#!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "X_R8NlJD0xYP"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "def objective_accuracy(trial):\n",
        "  \n",
        "      num_leaves = trial.suggest_int('num_leaves', num_leaves_min, num_leaves_max) #int\n",
        "      min_child_samples = trial.suggest_int('min_child_samples', min_child_samples_min, min_child_samples_max) #int\n",
        "      n_estimators      = trial.suggest_int('n_estimators', n_estimators_min, n_estimators_max)#int\n",
        "      learning_rate     = trial.suggest_float('learning_rate', learning_rate_min, learning_rate_max)\n",
        "      subsample_for_bin = trial.suggest_int('subsample_for_bin', subsample_for_bin_min, subsample_for_bin_max) #int\n",
        "      min_split_gain    = trial.suggest_float('min_split_gain', min_split_gain_min, min_split_gain_max)\n",
        "      min_child_weight  = trial.suggest_float('min_child_weight', min_child_weight_min, min_child_weight_max)\n",
        "      reg_alpha         = trial.suggest_float('reg_alpha', reg_alpha_min, reg_alpha_max)\n",
        "      reg_lambda        = trial.suggest_float('reg_lambda', reg_lambda_min, reg_lambda_max)\n",
        "      max_depth = trial.suggest_int('max_depth', max_depth_min, max_depth_max)\n",
        "      bagging_fraction = trial.suggest_float('bagging_fraction', bagging_fraction_min, bagging_fraction_max)\n",
        "      pos_bagging_fraction = trial.suggest_float('pos_bagging_fraction', pos_bagging_fraction_min, pos_bagging_fraction_max)\n",
        "      neg_bagging_fraction = trial.suggest_float('neg_bagging_fraction', neg_bagging_fraction_min, neg_bagging_fraction_max)\n",
        "      bagging_freq = trial.suggest_int('bagging_freq', bagging_freq_min, bagging_freq_max)\n",
        "      feature_fraction = trial.suggest_float('feature_fraction', feature_fraction_min, feature_fraction_max)\n",
        "      feature_fraction_bynode = trial.suggest_float('feature_fraction_bynode', feature_fraction_bynode_min, feature_fraction_bynode_max)\n",
        "      extra_trees = trial.suggest_int('extra_trees', extra_trees_min, extra_trees_max)\n",
        "      #first_metric_only = trial.suggest_int('first_metric_only', first_metric_only_min, first_metric_only_max)\n",
        "      max_delta_step = trial.suggest_float('max_delta_step', max_delta_step_min, max_delta_step_max)\n",
        "      linear_lambda = trial.suggest_float('linear_lambda', linear_lambda_min, linear_lambda_max)\n",
        "      min_data_per_group = trial.suggest_int('min_data_per_group', min_data_per_group_min, min_data_per_group_max)\n",
        "      max_cat_threshold = trial.suggest_int('max_cat_threshold', max_cat_threshold_min, max_cat_threshold_max)\n",
        "      cat_l2 = trial.suggest_float('cat_l2', cat_l2_min, cat_l2_max)\n",
        "      cat_smooth = trial.suggest_float('cat_smooth', cat_smooth_min, cat_smooth_max)\n",
        "      max_cat_to_onehot = trial.suggest_int('max_cat_to_onehot', max_cat_to_onehot_min, max_cat_to_onehot_max)\n",
        "      top_k = trial.suggest_int('top_k', top_k_min, top_k_max)\n",
        "\n",
        "      final_model = lgb.LGBMClassifier(num_leaves       = num_leaves, \n",
        "                                      min_child_samples = min_child_samples, \n",
        "                                      n_estimators      = n_estimators,\n",
        "                                      learning_rate     = learning_rate,\n",
        "                                      subsample_for_bin = subsample_for_bin,\n",
        "                                      min_split_gain    = min_split_gain,\n",
        "                                      min_child_weight  = min_child_weight,\n",
        "                                      reg_alpha         = reg_alpha,\n",
        "                                      reg_lambda        = reg_lambda,\n",
        "                                      max_depth= -1,\n",
        "                                      n_jobs = -1\n",
        "                                      )\n",
        "      \n",
        "      kfold = KFold(n_splits = 3, shuffle = True)\n",
        "\n",
        "      return sklearn.model_selection.cross_val_score(final_model, x_wine, y_wine, n_jobs=-1, cv=kfold).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r62Ch5ng00NT",
        "outputId": "05e8015b-6c79-4043-daf8-028abeea7334"
      },
      "outputs": [],
      "source": [
        "def run_optuna_accuracy(n_trials=1024):\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective_accuracy, n_trials=n_trials, n_jobs = -1)\n",
        "    trial = study.best_trial\n",
        "    #print('Accuracy: {}'.format(trial.value))\n",
        "    #print(\"Best hyperparameters: {}\".format(trial.params))\n",
        "    return trial.value, study\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "trial, study = run_optuna_accuracy(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3216592016980555"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "odCO6YCmz1q4"
      },
      "outputs": [],
      "source": [
        "#tracking = []\n",
        "#for i in range(len(study.trials)):\n",
        "#  if i == 0: \n",
        "#    tracking.append(study.trials[i].value)\n",
        "#  elif tracking[i-1] > study.trials[i].value:\n",
        "#    tracking.append(tracking[i-1])\n",
        "#  else:\n",
        "#    tracking.append(study.trials[i].value)\n",
        "##tracking_sorted = sorted(tracking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ukqgm-fOHTVs"
      },
      "outputs": [],
      "source": [
        "#tracking_Optuna_Accuracy = tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "L8cqXHz06SXp",
        "outputId": "e0ea3abf-1a22-479f-b12c-fa76bb91b4c6"
      },
      "outputs": [],
      "source": [
        "#plt.plot(tracking);\n",
        "#plt.plot(tracking_sorted) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "dSnAebcQ04n8",
        "outputId": "e0275cf0-9485-43d1-af08-75042d2f3351"
      },
      "outputs": [],
      "source": [
        "#optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "PykRbFk506AF",
        "outputId": "b37580c8-b893-4d8f-f745-60affb470c52"
      },
      "outputs": [],
      "source": [
        "#optuna.visualization.plot_slice(study)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective_f1(trial):\n",
        "  \n",
        "      num_leaves = trial.suggest_int('num_leaves', num_leaves_min, num_leaves_max) #int\n",
        "      min_child_samples = trial.suggest_int('min_child_samples', min_child_samples_min, min_child_samples_max) #int\n",
        "      n_estimators      = trial.suggest_int('n_estimators', n_estimators_min, n_estimators_max)#int\n",
        "      learning_rate     = trial.suggest_float('learning_rate', learning_rate_min, learning_rate_max)\n",
        "      subsample_for_bin = trial.suggest_int('subsample_for_bin', subsample_for_bin_min, subsample_for_bin_max) #int\n",
        "      min_split_gain    = trial.suggest_float('min_split_gain', min_split_gain_min, min_split_gain_max)\n",
        "      min_child_weight  = trial.suggest_float('min_child_weight', min_child_weight_min, min_child_weight_max)\n",
        "      reg_alpha         = trial.suggest_float('reg_alpha', reg_alpha_min, reg_alpha_max)\n",
        "      reg_lambda        = trial.suggest_float('reg_lambda', reg_lambda_min, reg_lambda_max)\n",
        "      max_depth = trial.suggest_int('max_depth', max_depth_min, max_depth_max)\n",
        "      bagging_fraction = trial.suggest_float('bagging_fraction', bagging_fraction_min, bagging_fraction_max)\n",
        "      pos_bagging_fraction = trial.suggest_float('pos_bagging_fraction', pos_bagging_fraction_min, pos_bagging_fraction_max)\n",
        "      neg_bagging_fraction = trial.suggest_float('neg_bagging_fraction', neg_bagging_fraction_min, neg_bagging_fraction_max)\n",
        "      bagging_freq = trial.suggest_int('bagging_freq', bagging_freq_min, bagging_freq_max)\n",
        "      feature_fraction = trial.suggest_float('feature_fraction', feature_fraction_min, feature_fraction_max)\n",
        "      feature_fraction_bynode = trial.suggest_float('feature_fraction_bynode', feature_fraction_bynode_min, feature_fraction_bynode_max)\n",
        "      extra_trees = trial.suggest_int('extra_trees', extra_trees_min, extra_trees_max)\n",
        "      #first_metric_only = trial.suggest_int('first_metric_only', first_metric_only_min, first_metric_only_max)\n",
        "      max_delta_step = trial.suggest_float('max_delta_step', max_delta_step_min, max_delta_step_max)\n",
        "      linear_lambda = trial.suggest_float('linear_lambda', linear_lambda_min, linear_lambda_max)\n",
        "      min_data_per_group = trial.suggest_int('min_data_per_group', min_data_per_group_min, min_data_per_group_max)\n",
        "      max_cat_threshold = trial.suggest_int('max_cat_threshold', max_cat_threshold_min, max_cat_threshold_max)\n",
        "      cat_l2 = trial.suggest_float('cat_l2', cat_l2_min, cat_l2_max)\n",
        "      cat_smooth = trial.suggest_float('cat_smooth', cat_smooth_min, cat_smooth_max)\n",
        "      max_cat_to_onehot = trial.suggest_int('max_cat_to_onehot', max_cat_to_onehot_min, max_cat_to_onehot_max)\n",
        "      top_k = trial.suggest_int('top_k', top_k_min, top_k_max)\n",
        "\n",
        "      final_model = lgb.LGBMClassifier(num_leaves       = num_leaves, \n",
        "                                      min_child_samples = min_child_samples, \n",
        "                                      n_estimators      = n_estimators,\n",
        "                                      learning_rate     = learning_rate,\n",
        "                                      subsample_for_bin = subsample_for_bin,\n",
        "                                      min_split_gain    = min_split_gain,\n",
        "                                      min_child_weight  = min_child_weight,\n",
        "                                      reg_alpha         = reg_alpha,\n",
        "                                      reg_lambda        = reg_lambda,\n",
        "                                      max_depth= -1,\n",
        "                                      n_jobs = -1\n",
        "                                      )\n",
        "      \n",
        "      kfold = KFold(n_splits = 3, shuffle = True)\n",
        "\n",
        "      return sklearn.model_selection.cross_val_score(final_model, x_wine, y_wine, n_jobs=-1, scoring='f1_weighted', cv=kfold).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_optuna_f1(n_trials=1024):\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective_f1, n_trials=n_trials, n_jobs = -1)\n",
        "    trial = study.best_trial\n",
        "    #print('F1: {}'.format(trial.value))\n",
        "    #print(\"Best hyperparameters: {}\".format(trial.params))\n",
        "    return trial.value, study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "trial, study = run_optuna_f1(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tracking = []\n",
        "#for i in range(len(study.trials)):\n",
        "#  if i == 0: \n",
        "#    tracking.append(study.trials[i].value)\n",
        "#  elif tracking[i-1] > study.trials[i].value:\n",
        "#    tracking.append(tracking[i-1])\n",
        "#  else:\n",
        "#    tracking.append(study.trials[i].value)\n",
        "##tracking_sorted = sorted(tracking)\n",
        "#\n",
        "#tracking_Optuna_F1 = tracking\n",
        "#\n",
        "#plt.plot(tracking);\n",
        "##plt.plot(tracking_sorted) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective_auc(trial):\n",
        "  \n",
        "      num_leaves = trial.suggest_int('num_leaves', num_leaves_min, num_leaves_max) #int\n",
        "      min_child_samples = trial.suggest_int('min_child_samples', min_child_samples_min, min_child_samples_max) #int\n",
        "      n_estimators      = trial.suggest_int('n_estimators', n_estimators_min, n_estimators_max)#int\n",
        "      learning_rate     = trial.suggest_float('learning_rate', learning_rate_min, learning_rate_max)\n",
        "      subsample_for_bin = trial.suggest_int('subsample_for_bin', subsample_for_bin_min, subsample_for_bin_max) #int\n",
        "      min_split_gain    = trial.suggest_float('min_split_gain', min_split_gain_min, min_split_gain_max)\n",
        "      min_child_weight  = trial.suggest_float('min_child_weight', min_child_weight_min, min_child_weight_max)\n",
        "      reg_alpha         = trial.suggest_float('reg_alpha', reg_alpha_min, reg_alpha_max)\n",
        "      reg_lambda        = trial.suggest_float('reg_lambda', reg_lambda_min, reg_lambda_max)\n",
        "      max_depth = trial.suggest_int('max_depth', max_depth_min, max_depth_max)\n",
        "      bagging_fraction = trial.suggest_float('bagging_fraction', bagging_fraction_min, bagging_fraction_max)\n",
        "      pos_bagging_fraction = trial.suggest_float('pos_bagging_fraction', pos_bagging_fraction_min, pos_bagging_fraction_max)\n",
        "      neg_bagging_fraction = trial.suggest_float('neg_bagging_fraction', neg_bagging_fraction_min, neg_bagging_fraction_max)\n",
        "      bagging_freq = trial.suggest_int('bagging_freq', bagging_freq_min, bagging_freq_max)\n",
        "      feature_fraction = trial.suggest_float('feature_fraction', feature_fraction_min, feature_fraction_max)\n",
        "      feature_fraction_bynode = trial.suggest_float('feature_fraction_bynode', feature_fraction_bynode_min, feature_fraction_bynode_max)\n",
        "      extra_trees = trial.suggest_int('extra_trees', extra_trees_min, extra_trees_max)\n",
        "      #first_metric_only = trial.suggest_int('first_metric_only', first_metric_only_min, first_metric_only_max)\n",
        "      max_delta_step = trial.suggest_float('max_delta_step', max_delta_step_min, max_delta_step_max)\n",
        "      linear_lambda = trial.suggest_float('linear_lambda', linear_lambda_min, linear_lambda_max)\n",
        "      min_data_per_group = trial.suggest_int('min_data_per_group', min_data_per_group_min, min_data_per_group_max)\n",
        "      max_cat_threshold = trial.suggest_int('max_cat_threshold', max_cat_threshold_min, max_cat_threshold_max)\n",
        "      cat_l2 = trial.suggest_float('cat_l2', cat_l2_min, cat_l2_max)\n",
        "      cat_smooth = trial.suggest_float('cat_smooth', cat_smooth_min, cat_smooth_max)\n",
        "      max_cat_to_onehot = trial.suggest_int('max_cat_to_onehot', max_cat_to_onehot_min, max_cat_to_onehot_max)\n",
        "      top_k = trial.suggest_int('top_k', top_k_min, top_k_max)\n",
        "\n",
        "      final_model = lgb.LGBMClassifier(num_leaves       = num_leaves, \n",
        "                                      min_child_samples = min_child_samples, \n",
        "                                      n_estimators      = n_estimators,\n",
        "                                      learning_rate     = learning_rate,\n",
        "                                      subsample_for_bin = subsample_for_bin,\n",
        "                                      min_split_gain    = min_split_gain,\n",
        "                                      min_child_weight  = min_child_weight,\n",
        "                                      reg_alpha         = reg_alpha,\n",
        "                                      reg_lambda        = reg_lambda,\n",
        "                                      max_depth= -1,\n",
        "                                      n_jobs = -1\n",
        "                                      )\n",
        "      \n",
        "      kfold = KFold(n_splits = 3, shuffle = True)\n",
        "\n",
        "      return sklearn.model_selection.cross_val_score(final_model, x_wine, y_wine, n_jobs=-1, scoring='roc_auc_ovr_weighted', cv=kfold).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_optuna_auc(n_trials=1024):\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective_auc, n_trials=n_trials, n_jobs = -1)\n",
        "    trial = study.best_trial\n",
        "    #print('AUC: {}'.format(trial.value))\n",
        "    #print(\"Best hyperparameters: {}\".format(trial.params))\n",
        "    return trial.value, study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "trial, study = run_optuna_auc(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tracking = []\n",
        "#for i in range(len(study.trials)):\n",
        "#  if i == 0: \n",
        "#    tracking.append(study.trials[i].value)\n",
        "#  elif tracking[i-1] > study.trials[i].value:\n",
        "#    tracking.append(tracking[i-1])\n",
        "#  else:\n",
        "#    tracking.append(study.trials[i].value)\n",
        "##tracking_sorted = sorted(tracking)\n",
        "#\n",
        "#tracking_Optuna_AUC = tracking\n",
        "#\n",
        "#plt.plot(tracking);\n",
        "##plt.plot(tracking_sorted) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O554Q6QTEVSZ"
      },
      "source": [
        "# Análise Comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "fQLG5-KOEa-j",
        "outputId": "475764bd-0f8b-4a28-dfbc-06b9f8e93d0d"
      },
      "outputs": [],
      "source": [
        "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
        "#\n",
        "#ax1.set_title('PSO X Gerações')\n",
        "#ax2.set_title('PSO X Avaliações')\n",
        "#\n",
        "#ax1.plot(tracking_PSO_Accuracy)\n",
        "#ax2.plot(Accuracy_PSO)\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "rQXRvTMeGdtO",
        "outputId": "3e5b32fe-6843-4453-c4c0-c72f988355e3"
      },
      "outputs": [],
      "source": [
        "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
        "#\n",
        "#ax1.set_title('GA X Gerações')\n",
        "#ax2.set_title('GA X Avaliações')\n",
        "#\n",
        "#ax1.plot(tracking_GA_Accuracy)\n",
        "#ax2.plot(Accuracy_GA)\n",
        "#plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gráficos Comparativos Acurácia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "wPAE1qekG2QL",
        "outputId": "ed21fdf7-0168-43ed-be6f-6a7d40ee56a7"
      },
      "outputs": [],
      "source": [
        "#from IPython.core.pylabtools import figsize\n",
        "#from matplotlib.pyplot import figure\n",
        "#import matplotlib.patches as mpatches\n",
        "#\n",
        "#plt.figure(figsize=(12, 6))\n",
        "#red_patch = mpatches.Patch(color='red', label='PSO')\n",
        "#blue_patch = mpatches.Patch(color='blue', label='GA')\n",
        "#green_patch = mpatches.Patch(color='green', label='Optuna')\n",
        "##black_patch = mpatches.Patch(color='black', label='GridSearch')\n",
        "#\n",
        "#plt.legend(handles=[red_patch, blue_patch, green_patch])\n",
        "#plt.plot(Accuracy_GA, color = 'blue', linewidth=1, linestyle='-', )\n",
        "#plt.plot(Accuracy_PSO, color = 'red', linewidth=1, linestyle='-')\n",
        "#plt.plot(tracking_Optuna_Accuracy, color = 'green', linewidth=1, linestyle='-')\n",
        "##plt.plot(tracking_GS, color = 'black', linewidth=3, linestyle='-')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "hkxfnJJoKHia",
        "outputId": "b1c67284-9c27-4868-c7c1-54368e704ec5"
      },
      "outputs": [],
      "source": [
        "#fig, ax = plt.subplots(2, 2, figsize=(25,15))\n",
        "#\n",
        "#ax[0, 0].set_title(f'Genetic Algorithm (GA) - Accuracy: {max(tracking_GA_Accuracy)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#ax[0, 1].set_title(f'Particle Swarm Optimization (PSO) - Accuracy: {max(tracking_PSO_Accuracy)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#\n",
        "#ax[1, 0].set_title(f'Grid Search - Accuracy: {max(tracking_GS_Accuracy)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#ax[1, 1].set_title(f'Optuna - Accuracy: {max(tracking_Optuna_Accuracy)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#\n",
        "#ax[0,0].plot(tracking_GA_Accuracy, color = 'blue', linewidth=3, linestyle='-', )\n",
        "#ax[0,1].plot(tracking_PSO_Accuracy, color = 'red', linewidth=3, linestyle='-')\n",
        "#\n",
        "#ax[1,0].plot(tracking_GS_Accuracy, color = 'black', linewidth=3, linestyle='-')\n",
        "#ax[1,1].plot(tracking_Optuna_Accuracy, color = 'green', linewidth=3, linestyle='-')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "#plt.figure(figsize=(12, 6))\n",
        "#red_patch = mpatches.Patch(color='red', label='PSO')\n",
        "#blue_patch = mpatches.Patch(color='blue', label='GA')\n",
        "#green_patch = mpatches.Patch(color='green', label='Optuna')\n",
        "##black_patch = mpatches.Patch(color='black', label='GridSearch')\n",
        "#\n",
        "#plt.legend(handles=[red_patch, blue_patch, green_patch])\n",
        "#plt.plot(F1_GA, color = 'blue', linewidth=1, linestyle='-', )\n",
        "#plt.plot(F1_PSO, color = 'red', linewidth=1, linestyle='-')\n",
        "#plt.plot(tracking_Optuna_F1, color = 'green', linewidth=1, linestyle='-')\n",
        "##plt.plot(tracking_GS, color = 'black', linewidth=3, linestyle='-')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "#fig, ax = plt.subplots(2, 2, figsize=(25,15))\n",
        "#\n",
        "#ax[0, 0].set_title(f'Genetic Algorithm (GA) - Accuracy: {max(tracking_GA_F1)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#ax[0, 1].set_title(f'Particle Swarm Optimization (PSO) - Accuracy: {max(tracking_PSO_F1)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#\n",
        "#ax[1, 0].set_title(f'Grid Search - Accuracy: {max(tracking_GS_F1)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#ax[1, 1].set_title(f'Optuna - Accuracy: {max(tracking_Optuna_F1)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#\n",
        "#ax[0,0].plot(tracking_GA_F1, color = 'blue', linewidth=3, linestyle='-', )\n",
        "#ax[0,1].plot(tracking_PSO_F1, color = 'red', linewidth=3, linestyle='-')\n",
        "#\n",
        "#ax[1,0].plot(tracking_GS_F1, color = 'black', linewidth=3, linestyle='-')\n",
        "#ax[1,1].plot(tracking_Optuna_F1, color = 'green', linewidth=3, linestyle='-')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ROC AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "#plt.figure(figsize=(12, 6))\n",
        "#red_patch = mpatches.Patch(color='red', label='PSO')\n",
        "#blue_patch = mpatches.Patch(color='blue', label='GA')\n",
        "#green_patch = mpatches.Patch(color='green', label='Optuna')\n",
        "##black_patch = mpatches.Patch(color='black', label='GridSearch')\n",
        "#\n",
        "#plt.legend(handles=[red_patch, blue_patch, green_patch])\n",
        "#plt.plot(AUC_GA, color = 'blue', linewidth=1, linestyle='-', )\n",
        "#plt.plot(AUC_PSO, color = 'red', linewidth=1, linestyle='-')\n",
        "#plt.plot(tracking_Optuna_AUC, color = 'green', linewidth=1, linestyle='-')\n",
        "##plt.plot(tracking_GS, color = 'black', linewidth=3, linestyle='-')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "#fig, ax = plt.subplots(2, 2, figsize=(25,15))\n",
        "#\n",
        "#ax[0, 0].set_title(f'Genetic Algorithm (GA) - Accuracy: {max(tracking_GA_AUC)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#ax[0, 1].set_title(f'Particle Swarm Optimization (PSO) - Accuracy: {max(tracking_PSO_AUC)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#\n",
        "#ax[1, 0].set_title(f'Grid Search - Accuracy: {max(tracking_GS_AUC)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#ax[1, 1].set_title(f'Optuna - Accuracy: {max(tracking_Optuna_AUC)}', fontdict={'fontsize': 20, 'fontweight': 'medium'})\n",
        "#\n",
        "#ax[0,0].plot(tracking_GA_AUC, color = 'blue', linewidth=3, linestyle='-', )\n",
        "#ax[0,1].plot(tracking_PSO_AUC, color = 'red', linewidth=3, linestyle='-')\n",
        "#\n",
        "#ax[1,0].plot(tracking_GS_AUC, color = 'black', linewidth=3, linestyle='-')\n",
        "#ax[1,1].plot(tracking_Optuna_AUC, color = 'green', linewidth=3, linestyle='-')\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import uniform\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def random_search_int_range(min_l, max_l):\n",
        "    return [int(i) for i in np.arange(randint.ppf(0.01, min_l, max_l + 2),randint.ppf(0.99, min_l, max_l + 2))]\n",
        "\n",
        "\n",
        "def run_random_search_accuracy(iterations = 1024):\n",
        "    param_distribution = {\n",
        "        'num_leaves' : random_search_int_range(num_leaves_min, num_leaves_max),\n",
        "        'min_child_samples' : random_search_int_range(min_child_samples_min, min_child_samples_max),\n",
        "        'n_estimators' : random_search_int_range(n_estimators_min, n_estimators_max),\n",
        "        'learning_rate' : uniform(learning_rate_min, learning_rate_max),\n",
        "        'subsample_for_bin' : random_search_int_range(subsample_for_bin_min, subsample_for_bin_max),\n",
        "        'min_split_gain' : uniform(min_split_gain_min, min_split_gain_max),\n",
        "        'min_child_weight' : uniform(min_child_weight_min, min_child_weight_max),\n",
        "        'reg_alpha' : uniform(reg_alpha_min, reg_alpha_max),\n",
        "        'reg_lambda' : uniform(reg_lambda_min, reg_lambda_max),\n",
        "        'max_depth' : random_search_int_range(max_depth_min, max_depth_max),\n",
        "        'bagging_fraction' : uniform(bagging_fraction_min, bagging_fraction_max),\n",
        "        'pos_bagging_fraction' : uniform(pos_bagging_fraction_min, pos_bagging_fraction_max),\n",
        "        'neg_bagging_fraction' : uniform(neg_bagging_fraction_min, neg_bagging_fraction_max),\n",
        "        'bagging_freq' : random_search_int_range(bagging_freq_min, bagging_freq_max),\n",
        "        'feature_fraction' : uniform(feature_fraction_min, feature_fraction_max),\n",
        "        'feature_fraction_bynode' : uniform(feature_fraction_bynode_min, feature_fraction_bynode_max),\n",
        "        'extra_trees' : [True, False],\n",
        "        'max_delta_step' : uniform(max_delta_step_min, max_delta_step_max),\n",
        "        'linear_lambda' : uniform(linear_lambda_min, linear_lambda_max),\n",
        "        'min_data_per_group' : random_search_int_range(min_data_per_group_min, min_data_per_group_max),\n",
        "        'max_cat_threshold' : random_search_int_range(max_cat_threshold_min, max_cat_threshold_max),\n",
        "        'cat_l2' : uniform(cat_l2_min, cat_l2_max),\n",
        "        'cat_smooth' : uniform(cat_smooth_min, cat_smooth_max),\n",
        "        'max_cat_to_onehot' : random_search_int_range(max_cat_to_onehot_min, max_cat_to_onehot_max),\n",
        "        'top_k' : random_search_int_range(top_k_min, top_k_max),\n",
        "        'n_jobs' : [-1]\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    kfold = KFold(n_splits = 3, shuffle = True)\n",
        "\n",
        "    random_search_accuracy = RandomizedSearchCV(lgb.LGBMClassifier(), param_distribution, n_iter = iterations, n_jobs = 10, cv=kfold, verbose=False)\n",
        "    random_search_accuracy.fit(x_wine, y_wine)\n",
        "\n",
        "    return random_search_accuracy.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import uniform\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def random_search_int_range(min_l, max_l):\n",
        "    return [int(i) for i in np.arange(randint.ppf(0.01, min_l, max_l + 2),randint.ppf(0.99, min_l, max_l + 2))]\n",
        "\n",
        "\n",
        "def run_random_search_f1(iterations = 1024):\n",
        "    param_distribution = {\n",
        "        'num_leaves' : random_search_int_range(num_leaves_min, num_leaves_max),\n",
        "        'min_child_samples' : random_search_int_range(min_child_samples_min, min_child_samples_max),\n",
        "        'n_estimators' : random_search_int_range(n_estimators_min, n_estimators_max),\n",
        "        'learning_rate' : uniform(learning_rate_min, learning_rate_max),\n",
        "        'subsample_for_bin' : random_search_int_range(subsample_for_bin_min, subsample_for_bin_max),\n",
        "        'min_split_gain' : uniform(min_split_gain_min, min_split_gain_max),\n",
        "        'min_child_weight' : uniform(min_child_weight_min, min_child_weight_max),\n",
        "        'reg_alpha' : uniform(reg_alpha_min, reg_alpha_max),\n",
        "        'reg_lambda' : uniform(reg_lambda_min, reg_lambda_max),\n",
        "        'max_depth' : random_search_int_range(max_depth_min, max_depth_max),\n",
        "        'bagging_fraction' : uniform(bagging_fraction_min, bagging_fraction_max),\n",
        "        'pos_bagging_fraction' : uniform(pos_bagging_fraction_min, pos_bagging_fraction_max),\n",
        "        'neg_bagging_fraction' : uniform(neg_bagging_fraction_min, neg_bagging_fraction_max),\n",
        "        'bagging_freq' : random_search_int_range(bagging_freq_min, bagging_freq_max),\n",
        "        'feature_fraction' : uniform(feature_fraction_min, feature_fraction_max),\n",
        "        'feature_fraction_bynode' : uniform(feature_fraction_bynode_min, feature_fraction_bynode_max),\n",
        "        'extra_trees' : [True, False],\n",
        "        'max_delta_step' : uniform(max_delta_step_min, max_delta_step_max),\n",
        "        'linear_lambda' : uniform(linear_lambda_min, linear_lambda_max),\n",
        "        'min_data_per_group' : random_search_int_range(min_data_per_group_min, min_data_per_group_max),\n",
        "        'max_cat_threshold' : random_search_int_range(max_cat_threshold_min, max_cat_threshold_max),\n",
        "        'cat_l2' : uniform(cat_l2_min, cat_l2_max),\n",
        "        'cat_smooth' : uniform(cat_smooth_min, cat_smooth_max),\n",
        "        'max_cat_to_onehot' : random_search_int_range(max_cat_to_onehot_min, max_cat_to_onehot_max),\n",
        "        'top_k' : random_search_int_range(top_k_min, top_k_max),\n",
        "        'n_jobs' : [-1]\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    kfold = KFold(n_splits = 3, shuffle = True)\n",
        "\n",
        "    random_search_accuracy = RandomizedSearchCV(lgb.LGBMClassifier(), param_distribution, n_iter = iterations, n_jobs = 10, cv=kfold, verbose=False, scoring='f1_weighted')\n",
        "    random_search_accuracy.fit(x_wine, y_wine)\n",
        "\n",
        "    return random_search_accuracy.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6694570487017927"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_random_search_f1(iterations = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import uniform\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "def random_search_int_range(min_l, max_l):\n",
        "    return [int(i) for i in np.arange(randint.ppf(0.01, min_l, max_l + 2),randint.ppf(0.99, min_l, max_l + 2))]\n",
        "\n",
        "\n",
        "def run_random_search_auc(iterations = 1024):\n",
        "    param_distribution = {\n",
        "        'num_leaves' : random_search_int_range(num_leaves_min, num_leaves_max),\n",
        "        'min_child_samples' : random_search_int_range(min_child_samples_min, min_child_samples_max),\n",
        "        'n_estimators' : random_search_int_range(n_estimators_min, n_estimators_max),\n",
        "        'learning_rate' : uniform(learning_rate_min, learning_rate_max),\n",
        "        'subsample_for_bin' : random_search_int_range(subsample_for_bin_min, subsample_for_bin_max),\n",
        "        'min_split_gain' : uniform(min_split_gain_min, min_split_gain_max),\n",
        "        'min_child_weight' : uniform(min_child_weight_min, min_child_weight_max),\n",
        "        'reg_alpha' : uniform(reg_alpha_min, reg_alpha_max),\n",
        "        'reg_lambda' : uniform(reg_lambda_min, reg_lambda_max),\n",
        "        'max_depth' : random_search_int_range(max_depth_min, max_depth_max),\n",
        "        'bagging_fraction' : uniform(bagging_fraction_min, bagging_fraction_max),\n",
        "        'pos_bagging_fraction' : uniform(pos_bagging_fraction_min, pos_bagging_fraction_max),\n",
        "        'neg_bagging_fraction' : uniform(neg_bagging_fraction_min, neg_bagging_fraction_max),\n",
        "        'bagging_freq' : random_search_int_range(bagging_freq_min, bagging_freq_max),\n",
        "        'feature_fraction' : uniform(feature_fraction_min, feature_fraction_max),\n",
        "        'feature_fraction_bynode' : uniform(feature_fraction_bynode_min, feature_fraction_bynode_max),\n",
        "        'extra_trees' : [True, False],\n",
        "        'max_delta_step' : uniform(max_delta_step_min, max_delta_step_max),\n",
        "        'linear_lambda' : uniform(linear_lambda_min, linear_lambda_max),\n",
        "        'min_data_per_group' : random_search_int_range(min_data_per_group_min, min_data_per_group_max),\n",
        "        'max_cat_threshold' : random_search_int_range(max_cat_threshold_min, max_cat_threshold_max),\n",
        "        'cat_l2' : uniform(cat_l2_min, cat_l2_max),\n",
        "        'cat_smooth' : uniform(cat_smooth_min, cat_smooth_max),\n",
        "        'max_cat_to_onehot' : random_search_int_range(max_cat_to_onehot_min, max_cat_to_onehot_max),\n",
        "        'top_k' : random_search_int_range(top_k_min, top_k_max),\n",
        "        'n_jobs' : [-1]\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    kfold = KFold(n_splits = 3, shuffle = True)\n",
        "\n",
        "    random_search_accuracy = RandomizedSearchCV(lgb.LGBMClassifier(), param_distribution, n_iter = iterations, n_jobs = 10, cv=kfold, verbose=False, scoring='roc_auc_ovr_weighted')\n",
        "    random_search_accuracy.fit(x_wine, y_wine)\n",
        "\n",
        "    return random_search_accuracy.best_score_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gerando Dados Para Análise "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from os import system\n",
        "\n",
        "def full_run(iterations):\n",
        "    filename = './lightGBM_wine_data.csv'\n",
        "\n",
        "    try:\n",
        "        lightGBM_data = pd.read_csv(filename)\n",
        "    except:\n",
        "        open(filename, \"a\")\n",
        "        lightGBM_data = pd.DataFrame(columns=['Algorithm', 'Accuracy', 'F1', 'AUC'])\n",
        "\n",
        "\n",
        "    for i in tqdm(range(iterations)):\n",
        "        accuracy_pso, _, _ = run_accuracy_pso()\n",
        "        f1_pso, _, _ = run_f1_pso()\n",
        "        auc_pso, _, _ = run_auc_pso()\n",
        "        temp = pd.DataFrame({'Algorithm' : ['PSO'], \n",
        "                            'Accuracy' :[-accuracy_pso[0]], \n",
        "                            'F1' : [-f1_pso[0]], \n",
        "                            'AUC' : [-auc_pso[0]]})\n",
        "        #lightGBM_data = lightGBM_data.append(temp, ignore_index = True)\n",
        "        lightGBM_data = pd.concat([lightGBM_data, temp], ignore_index=True)\n",
        "        lightGBM_data[['Algorithm', 'Accuracy', 'F1', 'AUC']].to_csv(filename)\n",
        "        \n",
        "        accuracy_ga, _, _ = run_accuracy_ga()\n",
        "        f1_ga, _, _ = run_f1_ga()\n",
        "        auc_ga, _, _ = run_auc_ga()\n",
        "        temp = pd.DataFrame({'Algorithm' : ['GA'], \n",
        "                            'Accuracy' :[-accuracy_ga[0]], \n",
        "                            'F1' : [-f1_ga[0]], \n",
        "                            'AUC' : [-auc_ga[0]]})\n",
        "        #lightGBM_data = lightGBM_data.append(temp, ignore_index = True)\n",
        "        lightGBM_data = pd.concat([lightGBM_data, temp], ignore_index=True)\n",
        "        lightGBM_data[['Algorithm', 'Accuracy', 'F1', 'AUC']].to_csv(filename)\n",
        "        \n",
        "        accuracy_optuna, _ = run_optuna_accuracy()\n",
        "        f1_optuna, _ = run_optuna_f1()\n",
        "        auc_optuna, _ = run_optuna_auc()\n",
        "        temp = pd.DataFrame({'Algorithm' : ['Optuna'], \n",
        "                            'Accuracy' :[accuracy_optuna], \n",
        "                            'F1' : [f1_optuna], \n",
        "                            'AUC' : [auc_optuna]})\n",
        "        #lightGBM_data = lightGBM_data.append(temp, ignore_index = True)\n",
        "        lightGBM_data = pd.concat([lightGBM_data, temp], ignore_index=True)\n",
        "        lightGBM_data[['Algorithm', 'Accuracy', 'F1', 'AUC']].to_csv(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from os import system\n",
        "\n",
        "def full_run_pso(iterations):\n",
        "    filename = './lightGBM_wine_data.csv'\n",
        "\n",
        "    try:\n",
        "        lightGBM_data = pd.read_csv(filename)\n",
        "    except:\n",
        "        open(filename, \"a\")\n",
        "        lightGBM_data = pd.DataFrame(columns=['Algorithm', 'Accuracy', 'F1', 'AUC'])\n",
        "\n",
        "\n",
        "    for i in tqdm(range(iterations)):\n",
        "        accuracy_pso, _, _ = run_accuracy_pso()\n",
        "        f1_pso, _, _ = run_f1_pso()\n",
        "        auc_pso, _, _ = run_auc_pso()\n",
        "        temp = pd.DataFrame({'Algorithm' : ['PSO'], \n",
        "                            'Accuracy' :[-accuracy_pso[0]], \n",
        "                            'F1' : [-f1_pso[0]], \n",
        "                            'AUC' : [-auc_pso[0]]})\n",
        "        #lightGBM_data = lightGBM_data.append(temp, ignore_index = True)\n",
        "        lightGBM_data = pd.concat([lightGBM_data, temp], ignore_index=True)\n",
        "        lightGBM_data[['Algorithm', 'Accuracy', 'F1', 'AUC']].to_csv(filename)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from os import system\n",
        "\n",
        "def full_run_ga(iterations):\n",
        "    filename = './lightGBM_wine_data.csv'\n",
        "\n",
        "    try:\n",
        "        lightGBM_data = pd.read_csv(filename)\n",
        "    except:\n",
        "        open(filename, \"a\")\n",
        "        lightGBM_data = pd.DataFrame(columns=['Algorithm', 'Accuracy', 'F1', 'AUC'])\n",
        "\n",
        "\n",
        "    for i in tqdm(range(iterations)):\n",
        "\n",
        "        accuracy_ga, _, _ = run_accuracy_ga()\n",
        "        f1_ga, _, _ = run_f1_ga()\n",
        "        auc_ga, _, _ = run_auc_ga()\n",
        "        temp = pd.DataFrame({'Algorithm' : ['GA'], \n",
        "                            'Accuracy' :[-accuracy_ga[0]], \n",
        "                            'F1' : [-f1_ga[0]], \n",
        "                            'AUC' : [-auc_ga[0]]})\n",
        "        #lightGBM_data = lightGBM_data.append(temp, ignore_index = True)\n",
        "        lightGBM_data = pd.concat([lightGBM_data, temp], ignore_index=True)\n",
        "        lightGBM_data[['Algorithm', 'Accuracy', 'F1', 'AUC']].to_csv(filename)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from os import system\n",
        "\n",
        "def full_run_optuna(iterations):\n",
        "    filename = './lightGBM_wine_data.csv'\n",
        "\n",
        "    try:\n",
        "        lightGBM_data = pd.read_csv(filename)\n",
        "    except:\n",
        "        open(filename, \"a\")\n",
        "        lightGBM_data = pd.DataFrame(columns=['Algorithm', 'Accuracy', 'F1', 'AUC'])\n",
        "\n",
        "\n",
        "    for i in tqdm(range(iterations)):      \n",
        "        accuracy_optuna, _ = run_optuna_accuracy()\n",
        "        f1_optuna, _ = run_optuna_f1()\n",
        "        auc_optuna, _ = run_optuna_auc()\n",
        "        temp = pd.DataFrame({'Algorithm' : ['Optuna'], \n",
        "                            'Accuracy' :[accuracy_optuna], \n",
        "                            'F1' : [f1_optuna], \n",
        "                            'AUC' : [auc_optuna]})\n",
        "        #lightGBM_data = lightGBM_data.append(temp, ignore_index = True)\n",
        "        lightGBM_data = pd.concat([lightGBM_data, temp], ignore_index=True)\n",
        "        lightGBM_data[['Algorithm', 'Accuracy', 'F1', 'AUC']].to_csv(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from os import system\n",
        "\n",
        "def full_run_random_searh(iterations):\n",
        "    filename = './lightGBM_wine_data.csv'\n",
        "\n",
        "    try:\n",
        "        Catboost_data = pd.read_csv(filename)\n",
        "    except:\n",
        "        open(filename, \"a\")\n",
        "        Catboost_data = pd.DataFrame(columns=['Algorithm', 'Accuracy', 'F1', 'AUC'])\n",
        "\n",
        "\n",
        "    for i in tqdm(range(iterations)):\n",
        "\n",
        "        accuracy_rs = run_random_search_accuracy()\n",
        "        f1_rs = run_random_search_f1()\n",
        "        auc_rs = run_random_search_auc()\n",
        "        temp = pd.DataFrame({'Algorithm' : ['Random Search'], \n",
        "                            'Accuracy' :[accuracy_rs], \n",
        "                            'F1' : [f1_rs], \n",
        "                            'AUC' : [auc_rs]})\n",
        "        #Catboost_data = Catboost_data.append(temp, ignore_index = True)\n",
        "        Catboost_data = pd.concat([Catboost_data, temp], ignore_index=True)\n",
        "        Catboost_data[['Algorithm', 'Accuracy', 'F1', 'AUC']].to_csv(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.21512928 0.21512928 0.21512928 ... 0.64909169 0.57391464 0.34153335]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.18995378 0.19808371 0.11789818 ... 0.19819532 0.29723455 0.52876817]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.5        0.90740009 0.78603264 ... 0.5        0.83409533 0.5       ]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:28<00:00, 148.52s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.60576785 0.5        0.65186114 ... 0.79256086 0.5        0.5       ]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:31<00:00, 151.11s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.07963431 0.07963431 0.19760426 ... 0.07963431 0.2751356  0.32260008]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:28<00:00, 148.73s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.21932045 0.27104459 0.21932045 ... 0.27104459 0.34673103 0.26632277]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.80025416 0.77780806 0.61258309 ... 0.5        0.81280905 0.5       ]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:30<00:00, 150.88s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.21409824 0.21409824 0.21409824 ... 0.45330347 0.53625211 0.52375871]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.64739732 0.08589116 0.58081518 ... 0.08589116 0.1970211  0.08589116]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:26<00:00, 146.58s/it]\n",
            "100%|██████████| 1/1 [02:36<00:00, 156.01s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.24599126 0.26563587 0.16118491 ... 0.32540113 0.23586725 0.28598625]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:32<00:00, 152.31s/it]\n",
            "100%|██████████| 1/1 [02:26<00:00, 146.69s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.42820385 0.44595788 0.21931554 ... 0.28823609 0.46212816 0.26734072]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.1266634  0.3426063  0.08586794 ... 0.13870979 0.08586794 0.08586794]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:24<00:00, 144.28s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.15254691 0.08591547 0.67873057 ... 0.33550041 0.71942543 0.19137253]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.82422287 0.67691075 0.86497072 ... 0.77362479 0.53206406 0.78703815]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:27<00:00, 147.63s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.30752073 0.2658142  0.21983556 ... 0.28196977 0.30653549 0.56553556]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:26<00:00, 146.52s/it]\n",
            "100%|██████████| 1/1 [02:25<00:00, 145.81s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.1315017  0.31451204 0.23049772 ... 0.20151123 0.232712   0.08587334]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.79236488 0.80893712 0.5        ... 0.5        0.72518474 0.7859759 ]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:28<00:00, 148.05s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.30181857 0.4532863  0.27569364 ... 0.36446299 0.21931064 0.64073551]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.30191101 0.33299791 0.08587606 ... 0.08587606 0.08587606 0.2034278 ]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.5        0.5        0.77951157 ... 0.78544696 0.73775292 0.61317104]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:21<00:00, 141.88s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.31959387 0.21827797 0.63237523 ... 0.27048206 0.21827797 0.25745557]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.7810242  0.5        0.80257351 ... 0.83201158 0.5        0.60016302]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:27<00:00, 147.59s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.21409906 0.21409906 0.44960124 ... 0.21409906 0.42132839 0.70548205]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.11306167 0.30116378 0.07131838 ... 0.19666656 0.31948783 0.07131838]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.69452031 0.73709979 0.5        ... 0.60626919 0.65405365 0.8637655 ]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:28<00:00, 148.00s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.29222079 0.19086244 0.31538647 ... 0.08606152 0.30993046 0.19985349]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8068873  0.63825652 0.78837117 ... 0.5805504  0.73179499 0.8096647 ]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:23<00:00, 143.97s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.07954027 0.07954027 0.07954027 ... 0.07954027 0.27772513 0.07954027]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.83825634 0.80774463 0.84295604 ... 0.76590229 0.5        0.5       ]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:28<00:00, 148.19s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "9 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.27044199 0.21722895 0.29394234 ... 0.65379552 0.46632751 0.21722895]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.21005337 0.07232002 0.07232002 ... 0.07232002 0.264746   0.07232002]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:27<00:00, 147.70s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.33157952 0.21827715 0.37439802 ... 0.23132491 0.60731812 0.21827715]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.31705495 0.07993056 0.07993056 ... 0.07993056 0.34256458 0.32399703]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:29<00:00, 149.13s/it]\n",
            "100%|██████████| 1/1 [02:28<00:00, 148.68s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.21306067 0.35824899 0.3310963  ... 0.21306067 0.26269494 0.26580358]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.15676821 0.22357874 0.08595321 ... 0.58130907 0.08595321 0.31651527]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:27<00:00, 147.17s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.79035296 0.5        0.76516961 ... 0.5        0.5        0.64199386]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:29<00:00, 149.04s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.5        0.80752073 0.5        ... 0.61009943 0.6687216  0.76043298]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:28<00:00, 148.57s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.21774569 0.61150521 0.38902707 ... 0.37078491 0.40838366 0.27365528]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.07773127 0.30962242 0.1163502  ... 0.07773127 0.07773127 0.19522317]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:25<00:00, 145.84s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.22035639 0.22035639 0.38169946 ... 0.22035639 0.22035639 0.27779168]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:25<00:00, 145.32s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8162288  0.5        0.86106305 ... 0.65015034 0.5        0.85454871]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:27<00:00, 147.76s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "9 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.30759759 0.42615323 0.59950484 ... 0.38850787 0.63135401 0.45953055]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.08603496 0.12755034 0.08603496 ... 0.36691402 0.12104465 0.08603496]\n",
            "  warnings.warn(\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "6 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.80130781 0.5        0.75084868 ... 0.81885952 0.78508667 0.74422401]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:31<00:00, 151.33s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.4376066  0.27623409 0.27471003 ... 0.22977141 0.22977141 0.27938769]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:31<00:00, 151.06s/it]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 3072.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
            "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
            "    self._Booster = train(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
            "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
            "  File \"C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
            "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
            "lightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Felps\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.31709553 0.08597748 0.18981961 ... 0.08597748 0.08597748 0.65150782]\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [02:31<00:00, 151.58s/it]\n"
          ]
        }
      ],
      "source": [
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)\n",
        "full_run_random_searh(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_HsPc7BH-MWL",
        "iTAAhn6w-Be4",
        "F-WtiEIO0kFu",
        "vA6kphUO0vcT"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01d3490253a8464281845cb171385d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12434838d89048188eefe1af0332bfd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6288aa156624b108015ab993c54d52b",
              "IPY_MODEL_f45e5f0d4187404fb8f63acd3c26fe17",
              "IPY_MODEL_aaa16b6dbffd42ef973b1826e5ed2242"
            ],
            "layout": "IPY_MODEL_8721e5217b97444d948e5b85c6fd53c7"
          }
        },
        "124e5b4b5b3344f4abdc93628b112d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1614757884124ed487149ebed485833f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a32143976c744e5a388d7b343e7c054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20a38960e7374ab594f04f4b1c5e2321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f29547455ac4adb8edaa11d5839f5cb",
            "placeholder": "​",
            "style": "IPY_MODEL_1a32143976c744e5a388d7b343e7c054",
            "value": "100%"
          }
        },
        "54cbbc7ffbcc401abfbf3167f882019e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f124da663194ac0b073ab7a3fb168c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f29547455ac4adb8edaa11d5839f5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b3046c318d4fbcb66b198b50cd91e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3472a6094a4249a082f8dc630e5258": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1614757884124ed487149ebed485833f",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f124da663194ac0b073ab7a3fb168c3",
            "value": 32
          }
        },
        "7f079b743c6e4ad897ae55ba366a15b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8721e5217b97444d948e5b85c6fd53c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992dda0d38b145b88946b67edc62ab57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa16b6dbffd42ef973b1826e5ed2242": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d539e4a476cb4ae28e78769b17b97aa9",
            "placeholder": "​",
            "style": "IPY_MODEL_fb379b55e7bd4b3bb7ed4b0ec6390b2e",
            "value": " 32/32 [48:44&lt;00:00, 118.10s/it]"
          }
        },
        "ae818704a52542d696c8eb0c1c182a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76b3046c318d4fbcb66b198b50cd91e7",
            "placeholder": "​",
            "style": "IPY_MODEL_124e5b4b5b3344f4abdc93628b112d8f",
            "value": " 32/32 [15:48&lt;00:00, 30.29s/it]"
          }
        },
        "b504307a10f54034ad07715278fa1dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20a38960e7374ab594f04f4b1c5e2321",
              "IPY_MODEL_7c3472a6094a4249a082f8dc630e5258",
              "IPY_MODEL_ae818704a52542d696c8eb0c1c182a81"
            ],
            "layout": "IPY_MODEL_992dda0d38b145b88946b67edc62ab57"
          }
        },
        "b6288aa156624b108015ab993c54d52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d25235d18f8045de9948417d13538ef3",
            "placeholder": "​",
            "style": "IPY_MODEL_01d3490253a8464281845cb171385d59",
            "value": "100%"
          }
        },
        "d25235d18f8045de9948417d13538ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d539e4a476cb4ae28e78769b17b97aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f45e5f0d4187404fb8f63acd3c26fe17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f079b743c6e4ad897ae55ba366a15b9",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54cbbc7ffbcc401abfbf3167f882019e",
            "value": 32
          }
        },
        "fb379b55e7bd4b3bb7ed4b0ec6390b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
