{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../preprocessing/processed_data/wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'fixed acidity', 'volatile acidity', 'citric acid',\n",
       "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
       "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n",
       "       'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_wine = df[['quality']]\n",
    "x_wine = df.drop(columns='quality')\n",
    "x_wine = x_wine.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_wine.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import pickle\n",
    "from pymoo.algorithms.soo.nonconvex.pso import PSO, PSOAnimation\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.factory import get_termination\n",
    "from pymoo.core.callback import Callback\n",
    "\n",
    "import numpy as np\n",
    "def special_floor(x):\n",
    "    x = int(np.round(x))\n",
    "    if x == 0:\n",
    "        x = 1\n",
    "    return x\n",
    "\n",
    "ITERATIONS = 32\n",
    "POPULATION = 32\n",
    "\n",
    "DIMENSIONS = 16\n",
    "\n",
    "\n",
    "n_estimators_max = 1000\n",
    "learning_rate_max = 0.6\n",
    "subsample_max = 1.0\n",
    "colsample_bytree_max = 1.0\n",
    "gamma_max = 0.5\n",
    "max_depth_max = 10\n",
    "min_child_weight_max = 10\n",
    "reg_alpha_max = 0.1\n",
    "reg_lambda_max = 1\n",
    "scale_pos_weight_max = 10\n",
    "base_score_max = 1\n",
    "\n",
    "n_estimators_min = 10\n",
    "learning_rate_min = 0.0001\n",
    "subsample_min = 0.6\n",
    "colsample_bytree_min = 0.6\n",
    "gamma_min = 0\n",
    "max_depth_min = 3\n",
    "min_child_weight_min = 1\n",
    "reg_alpha_min = 0\n",
    "reg_lambda_min = 0\n",
    "scale_pos_weight_min = 1\n",
    "base_score_min = 0\n",
    "\n",
    "import numpy as np\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "\n",
    "class OptimizeWithF1(ElementwiseProblem):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(n_var= 11,\n",
    "                         n_obj=1,\n",
    "                         n_constr=11,\n",
    "                         types = np.array([int, float, float, float, float, int, int, float, float, float, float]),\n",
    "                         xl=np.array([\n",
    "                          n_estimators_min,\n",
    "                            learning_rate_min,\n",
    "                            subsample_min,\n",
    "                            colsample_bytree_min,\n",
    "                            gamma_min,\n",
    "                            max_depth_min,\n",
    "                            min_child_weight_min,\n",
    "                            reg_alpha_min,\n",
    "                            reg_lambda_min,\n",
    "                            scale_pos_weight_min,\n",
    "                            base_score_min\n",
    "                          ]),\n",
    "                         xu=np.array([\n",
    "                            n_estimators_max,\n",
    "                            learning_rate_max,\n",
    "                            subsample_max,\n",
    "                            colsample_bytree_max,\n",
    "                            gamma_max,\n",
    "                            max_depth_max,\n",
    "                            min_child_weight_max,\n",
    "                            reg_alpha_max,\n",
    "                            reg_lambda_max,\n",
    "                            scale_pos_weight_max,\n",
    "                            base_score_max,\n",
    "                            ])\n",
    "                        )\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        #num_leaves, min_child_samples, n_estimators, learning_rate, subsample_for_bin, min_split_gain, min_child_weight, reg_alpha, reg_lambda\n",
    "       \n",
    "        model_xgboost = xgb.XGBClassifier(\n",
    "                          n_estimators = int(np.round(x[0])),\n",
    "                          learning_rate = x[1],\n",
    "                          subsample = x[2],\n",
    "                          colsample_bytree = x[3],\n",
    "                          gamma = x[4],\n",
    "                          max_depth = special_floor(x[5]),\n",
    "                          min_child_weight = int(np.round(x[6])),\n",
    "                          reg_alpha = x[7],\n",
    "                          reg_lambda = x[8],\n",
    "                          scale_pos_weight = int(x[9]),\n",
    "                          base_score       = x[10],\n",
    "                          n_jobs = -1\n",
    "                                       )\n",
    "        \n",
    "        kfold = KFold(n_splits = 3, shuffle = True)\n",
    "\n",
    "        scores = cross_val_score(model_xgboost, x_wine, y_wine, cv = kfold, scoring='f1_weighted', n_jobs=-1)  \n",
    "        result = scores.mean()\n",
    "        out['F'] = -1 * result\n",
    "\n",
    "problemF1 = OptimizeWithF1()\n",
    "\n",
    "from pymoo.util.display.column import Column\n",
    "from pymoo.util.display.output import Output\n",
    "\n",
    "class MyOutput(Output):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        global pbar \n",
    "        pbar = tqdm(total=ITERATIONS)\n",
    "        self.score = Column(\"score\", width=13)\n",
    "        self.Parameters = Column(\"Parameters\", width=35)\n",
    "        self.columns += [self.score, self.Parameters]\n",
    "\n",
    "    def update(self, algorithm):\n",
    "        super().update(algorithm)\n",
    "        self.score.set(-np.min(algorithm.pop.get(\"F\")))\n",
    "        #self.Parameters.set(algorithm.pop.get(\"X\")[0])\n",
    "        pbar.update(1)\n",
    "        if pbar.n == ITERATIONS: pbar.close()\n",
    "        \n",
    "import numpy as np\n",
    "\n",
    "xl=np.array([n_estimators_min,\n",
    "             learning_rate_min,\n",
    "             subsample_min,\n",
    "             colsample_bytree_min,\n",
    "             gamma_min,\n",
    "             max_depth_min,\n",
    "             min_child_weight_min,\n",
    "             reg_alpha_min,\n",
    "             reg_lambda_min,\n",
    "             scale_pos_weight_min,\n",
    "             base_score_min])\n",
    "xu=np.array([n_estimators_max,\n",
    "             learning_rate_max,\n",
    "             subsample_max,\n",
    "             colsample_bytree_max,\n",
    "             gamma_max,\n",
    "             max_depth_max,\n",
    "             min_child_weight_max,\n",
    "             reg_alpha_max,\n",
    "             reg_lambda_max,\n",
    "             scale_pos_weight_max,\n",
    "             base_score_max])\n",
    "\n",
    "def PSO_Optimize_F1(values):\n",
    "    x = values[0] \n",
    "    model_xgboost = xgb.XGBClassifier(\n",
    "                          n_estimators = int(np.round(x[0])),\n",
    "                          learning_rate = x[1],\n",
    "                          subsample = x[2],\n",
    "                          colsample_bytree = x[3],\n",
    "                          gamma = x[4],\n",
    "                          max_depth = special_floor(x[5]),\n",
    "                          min_child_weight = int(np.round(x[6])),\n",
    "                          reg_alpha = x[7],\n",
    "                          reg_lambda = x[8],\n",
    "                          scale_pos_weight = int(x[9]),\n",
    "                          base_score       = x[10],\n",
    "                          n_jobs = -1\n",
    "                                    )\n",
    "    \n",
    "    kfold = KFold(n_splits = 10, shuffle = True)\n",
    "    \n",
    "    scores = cross_val_score(model_xgboost,  x_wine, y_wine, cv = kfold, n_jobs=-1, scoring='f1_weighted')  \n",
    "    result = scores.mean()     \n",
    "    if result == np.nan:\n",
    "        result = 0\n",
    "    print(result)\n",
    "    return -result\n",
    "\n",
    "from pymoo.algorithms.soo.nonconvex.pso import PSO\n",
    "\n",
    "# Define the number of cores you want to use\n",
    "n_cores = 16\n",
    "\n",
    "def run_f1_pso(ITERATIONS=2, POPULATION=3):\n",
    "    algorithm = PSO(pop_size = POPULATION, c1 = 1.5, c2 = 1.5, w = 0.5)\n",
    "\n",
    "    term = get_termination(\"n_gen\", ITERATIONS)\n",
    "\n",
    "    res = minimize(problemF1,\n",
    "                   algorithm,\n",
    "                   save_history=False,\n",
    "                   verbose=True,\n",
    "                   vtype = ['int', 'float', 'float', 'float', 'float', 'float', 'int', 'float', 'float', 'int', 'float'],\n",
    "                   output=MyOutput(),\n",
    "                   termination=term)\n",
    "\n",
    "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
    "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
    "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
    "    \n",
    "    return score_best_individual, parameters_best_individual, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_best_individual, parameters_best_individual, res = run_f1_pso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "def run_f1_ga(ITERATIONS = 32, POPULATION = 32):\n",
    "    algorithm = GA(pop_size=POPULATION)\n",
    "\n",
    "    term = get_termination(\"n_gen\", ITERATIONS)\n",
    "\n",
    "    res = minimize(problemF1,\n",
    "                algorithm,\n",
    "                save_history=False,\n",
    "                vtype = ['int', 'float', 'float', 'float', 'float', 'float', 'int', 'float', 'float', 'int', 'float'],\n",
    "                verbose=True,\n",
    "                output=MyOutput(),\n",
    "                termination = term)\n",
    "\n",
    "\n",
    "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
    "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
    "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
    "\n",
    "    #print(f'Best F1 Score {-score_best_individual}')\n",
    "    #print(f'Model parameters: \\n {parameters_best_individual}')\n",
    "    \n",
    "    return score_best_individual, parameters_best_individual, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with_vartype_list = [] \n",
    "#for i in range(100):\n",
    "#    score_best_individual, parameters_best_individual, res = run_f1_ga(10, 10)\n",
    "#    with_vartype_list.append(-score_best_individual[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "def run_f1_ga(ITERATIONS = 32, POPULATION = 32):\n",
    "    algorithm = GA(pop_size=POPULATION)\n",
    "\n",
    "    term = get_termination(\"n_gen\", ITERATIONS)\n",
    "\n",
    "    res = minimize(problemF1,\n",
    "                algorithm,\n",
    "                save_history=False,\n",
    "                verbose=True,\n",
    "                output=MyOutput(),\n",
    "                termination = term)\n",
    "\n",
    "\n",
    "    index_best_individual = np.where(res.pop.get('F') == np.min(res.pop.get('F')))[0][0]\n",
    "    score_best_individual = res.pop.get('F')[index_best_individual]\n",
    "    parameters_best_individual = res.pop.get('X')[index_best_individual]\n",
    "\n",
    "    #print(f'Best F1 Score {-score_best_individual}')\n",
    "    #print(f'Model parameters: \\n {parameters_best_individual}')\n",
    "    \n",
    "    return score_best_individual, parameters_best_individual, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without_vartype_list = [] \n",
    "#for i in range(100):\n",
    "#    score_best_individual, parameters_best_individual, res = run_f1_ga(10, 10)\n",
    "#    without_vartype_list.append(-score_best_individual[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.util.display.column import Column\n",
    "from pymoo.util.display.output import Output\n",
    "\n",
    "class MyOutput(Output):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        global pbar \n",
    "        pbar = tqdm(total=ITERATIONS)\n",
    "        self.score = Column(\"score\", width=13)\n",
    "        self.Parameters = Column(\"Parameters\", width=35)\n",
    "        self.columns += [self.score, self.Parameters]\n",
    "\n",
    "    def update(self, algorithm):\n",
    "        super().update(algorithm)\n",
    "        self.score.set(-np.min(algorithm.pop.get(\"F\")))\n",
    "        #self.Parameters.set(algorithm.pop.get(\"X\")[0])\n",
    "        pbar.update(1)\n",
    "        if pbar.n == ITERATIONS: pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.variable import Real, Integer, Choice, Binary\n",
    "\n",
    "\n",
    "class MixedVariableProblem(ElementwiseProblem):\n",
    "    def __init__(self, **kwargs):\n",
    "        #params reference 1\n",
    "        xgb_params = {\n",
    "        'n_estimators' : Integer(bounds=(3, 10000)), #high num\n",
    "        'learning_rate' : Real(bounds=(0.001, 0.3)),\n",
    "        'max_depth' : Integer(bounds=(3, 15)),\n",
    "        'subsample' : Real(bounds=(0.5, 1.0)),\n",
    "        'colsample_bytree' : Real(bounds=(0.5, 1.0)),\n",
    "        'gamma'            : Real(bounds=(0, 10)),\n",
    "        'min_child_weight' : Real(bounds=(0, 10)),\n",
    "        'reg_lambda'       : Real(bounds=(0, 1)),\n",
    "        'reg_alpha'        : Real(bounds=(0, 1)),\n",
    "        }\n",
    "        super().__init__(vars=xgb_params, n_obj=1, **kwargs)\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        n_estimators = X['n_estimators']\n",
    "        learning_rate = X['learning_rate']\n",
    "        max_depth = X['max_depth']\n",
    "        subsample = X['subsample']\n",
    "        colsample_bytree = X['colsample_bytree']\n",
    "        gamma = X['gamma']\n",
    "        min_child_weight = X['min_child_weight']\n",
    "        reg_lambda = X['reg_lambda']\n",
    "        reg_alpha = X['reg_alpha']\n",
    "        \n",
    "        model_xgboost = xgb.XGBClassifier(\n",
    "            n_estimators = n_estimators,\n",
    "            learning_rate = learning_rate,\n",
    "            max_depth = max_depth,\n",
    "            subsample = subsample,\n",
    "            colsample_bytree = colsample_bytree,\n",
    "            gamma = gamma,\n",
    "            min_child_weight = min_child_weight,\n",
    "            reg_lambda = reg_lambda,\n",
    "            reg_alpha = reg_alpha,\n",
    "            n_jobs = -1\n",
    "            )\n",
    "        \n",
    "        kfold = KFold(n_splits = 10, shuffle = True)\n",
    "        \n",
    "        scores = cross_val_score(model_xgboost,  x_wine, y_wine, cv = kfold, n_jobs=-1, scoring='f1_weighted')  \n",
    "        result = scores.mean()     \n",
    "        if result == np.nan:\n",
    "            result = 0\n",
    "        #print(result)\n",
    "        #return result\n",
    "        out[\"F\"] = -result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b54dbacc931423592bf44f01e22f6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603764674977461\n",
      "0.5585447156711691\n",
      "0.5683563479016474\n",
      "0.5783697479841305\n",
      "0.6495280759354054\n",
      "0.5775855831249915\n",
      "0.611049150650071\n",
      "0.5883142719508437\n",
      "0.5983453894984121\n",
      "0.557220320015371\n",
      "0.5863797086506161\n",
      "0.567275727681778\n",
      "0.5639282573955346\n",
      "0.5807761780173972\n",
      "0.5875179703060676\n",
      "0.5896034638879276\n",
      "0.5676557242046202\n",
      "0.5757135588918711\n",
      "0.5615024831585984\n",
      "0.5876653771950764\n",
      "0.6396292033264956\n",
      "0.5619429446723058\n",
      "0.5501956810029345\n",
      "0.5700358849942875\n",
      "0.5909852259034543\n",
      "0.5589014267904691\n",
      "0.5704972894590368\n",
      "0.5927076858095559\n",
      "0.6297649101290276\n",
      "0.6176886465534872\n",
      "0.5606067625255953\n",
      "0.5836848809392778\n",
      "0.5764494636960229\n",
      "0.567785312491312\n",
      "0.5611847207278593\n",
      "0.6007447088123821\n",
      "0.5626280424891547\n",
      "0.5917151314832225\n",
      "0.5899845476284911\n",
      "0.5912560999948177\n",
      "0.5692565571005821\n",
      "0.5879499168513378\n",
      "0.5609912758992806\n",
      "0.5818903521168626\n",
      "0.5669519562382431\n",
      "0.5993788819772825\n",
      "0.5752444733716421\n",
      "0.5640193985570635\n",
      "0.5790994412262886\n",
      "0.5592187052618721\n",
      "=======================================================================\n",
      "n_gen  |  n_eval  |     score     |              Parameters            \n",
      "=======================================================================\n",
      "     1 |       50 |  0.6495280759 |                                   -\n",
      "Best solution found: \n",
      "X = {'n_estimators': 61, 'learning_rate': 0.2983982485478404, 'max_depth': 8, 'subsample': 0.9667706923916846, 'colsample_bytree': 0.820945295484024, 'gamma': 0.32593139935786497, 'min_child_weight': 2.2285416793657333, 'reg_lambda': 0.6419693715535431, 'reg_alpha': 0.1773105432276213}\n",
      "F = [-0.64952808]\n"
     ]
    }
   ],
   "source": [
    "from pymoo.core.mixed import MixedVariableGA\n",
    "from pymoo.core.variable import Real, Integer\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "problem = MixedVariableProblem()\n",
    "\n",
    "algorithm = MixedVariableGA(pop=10)\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=('n_evals', 10),\n",
    "               verbose=True,\n",
    "               output=MyOutput(),\n",
    "               #seed=1,\n",
    "               )\n",
    "\n",
    "print(\"Best solution found: \\nX = %s\\nF = %s\" % (res.X, res.F))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
