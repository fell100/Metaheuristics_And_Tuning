{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Dataset Attributes\n",
    "<br>Age : age of the patient [years]\n",
    "<br>Sex : sex of the patient [M: Male, F: Female]\n",
    "<br>ChestPainType : chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n",
    "<br>RestingBP : resting blood pressure [mm Hg]\n",
    "<br>Cholesterol : serum cholesterol [mm/dl]\n",
    "<br>FastingBS : fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]\n",
    "<br>RestingECG : resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]\n",
    "<br>MaxHR : maximum heart rate achieved [Numeric value between 60 and 202]\n",
    "<br>ExerciseAngina : exercise-induced angina [Y: Yes, N: No]\n",
    "<br>Oldpeak : oldpeak = ST [Numeric value measured in depression]\n",
    "<br>ST_Slope : the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n",
    "<br>HeartDisease : output class [1: heart disease, 0: Normal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQR_method (df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and returns an index list corresponding to the observations \n",
    "    containing more than n outliers according to the Tukey IQR method.\n",
    "    \"\"\"\n",
    "    outlier_list = []\n",
    "    \n",
    "    for column in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[column], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[column],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        # Determining a list of indices of outliers\n",
    "        outlier_list_column = df[(df[column] < Q1 - outlier_step) | (df[column] > Q3 + outlier_step )].index\n",
    "        # appending the list of outliers \n",
    "        outlier_list.extend(outlier_list_column)\n",
    "        \n",
    "    # selecting observations containing more than x outliers\n",
    "    outlier_list = Counter(outlier_list)        \n",
    "    multiple_outliers = list( k for k, v in outlier_list.items() if v > n )\n",
    "    \n",
    "    # Calculate the number of records below and above lower and above bound value respectively\n",
    "    out1 = df[df[column] < Q1 - outlier_step]\n",
    "    out2 = df[df[column] > Q3 + outlier_step]\n",
    "    \n",
    "    print('Total number of deleted outliers is:', out1.shape[0]+out2.shape[0])\n",
    "    \n",
    "    return multiple_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = list(raw_df.loc[:,['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']])\n",
    "categorical_columns = list(raw_df.loc[:,['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of deleted outliers is: 16\n"
     ]
    }
   ],
   "source": [
    "# detecting outliers\n",
    "Outliers_IQR = IQR_method(raw_df,1,numerical_columns)\n",
    "\n",
    "# dropping outliers\n",
    "df = raw_df.drop(Outliers_IQR, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creating function for scaling\n",
    "def Standard_Scaler (df, col_names):\n",
    "    features = df[col_names]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    df[col_names] = features\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = numerical_columns\n",
    "X_train = Standard_Scaler (X_train, col_names)\n",
    "X_test = Standard_Scaler (X_test, col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_heart = np.concatenate((X_train, X_test), axis = 0)\n",
    "y_heart = np.concatenate((y_train, y_test), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(905, 15)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(905,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('heart.pkl', mode = 'wb') as f:\n",
    "  pickle.dump([x_heart, y_heart], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5ac1e257a3445902302263f7bb85e3e096a16fcac665c553104f20e5a7c6c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
